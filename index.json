[{"content":"\n\n## 什么是Tinypng\n\nTinypng 网站提供在线图片压缩服务，是所有图片压缩工具中最好用的之一，但有限制：批量最多处理 20 张，且每张大小不允许超过 5M。\n但网站同时也提供了开放了免费的 API ，API 取消了每张大小的限制，只限定每个月处理 500 张图片。\n\n## 如何使用API\n\n1. 在它网站上注册，获得专属的 API_KEY。\n2. 然后是安装 package：\n```\npip install --upgrade tinify\n```\n3. 接着上代码:\n```\nimport tinify\nimport os\n\ntinify.key = 'api_key'\npath = \"d:\\\\images\\\\photo\" # 图片存放的路径\n\nfor dirpath, dirs, files in os.walk(path):\n    for file in files:\n        imgpath = os.path.join(dirpath, file)\n        print(\"compressing ...\"+ imgpath)\n        tinify.from_file(imgpath).to_file(imgpath)\n```\n\n","cover":"","link":"tinypng.html","preview":"\u003cp\u003e写了一个适用tingpng api 批量压缩图片的脚本只用了几行, 真是快艹猛。\u003c/p\u003e\n","title":"Use tinypng api to compress image via python"},{"content":"\n\n确定自己win10版本高于大于18945 查看方法运行中执行winver [版本 10.0.xxxxx.*]，其中xxxxx大于18945即可\n在 %UserProfile% 文件夹下创建.wslconfig文件，内容为:\n\n```\n[wsl2]\nmemory=4GB\nswap=0\nlocalhostForwarding=true\n```\n\n其中4GB为制作Vmmem进程使用内存的大小，然后保存即可最好保存成ANSI编码或者UTF-8格式\n然后关闭linux子系统然后在cmd运行 wsl --shutdown 后再次打开linux子系统即可生效\n\n\n[1]https://github.com/microsoft/WSL/issues/4166\n\n[2]https://docs.microsoft.com/en-us/windows/wsl/release-notes#build-18945\n","cover":"","link":"wsl2_mem.html","preview":"\u003cp\u003ewsl2出现Vmmem内存占用过大问题解决方法。\u003c/p\u003e\n","title":"WSL 2 consumes massive amounts of RAM"},{"content":"\n\n## 15 pro Active key\n\n|- YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8 -|\n|- UG5J2-0ME12-M89WY-NPWXX-WQH88 -|\n|- UA5DR-2ZD4H-089FY-6YQ5T-YPRX6 -|\n|- GA590-86Y05-4806Y-X4PEE-ZV8E0 -|\n|- ZF582-0NW5N-H8D2P-0XZEE-Z22VA -|\n|- YA18K-0WY8P-H85DY-L4NZG-X7RAD -|\n","cover":"","link":"vmware15key.html","preview":"\u003cp\u003e.\u003c/p\u003e\n","title":"VMware Workstation 15 Pro active key"},{"content":"\n\n## Windows下查看文件hash\n\n\u003e 使用certutil命令查看文件的hash\n\n```cmd\ncertutil -hashfile filename MD5\ncertutil -hashfile filename SHA1\ncertutil -hashfile filename SHA256\n```\n","cover":"","link":"hash_windows.html","preview":"\u003cp\u003ewin下的hash命令。\u003c/p\u003e\n","title":"Hash cmd on win"},{"content":"\n\n\u003e 项目服务用java写的，跑在console下非常不安全，如遇意外挂掉没法自动拉起。需要类似superviser的守护软件管理起来，\n[NSSM](http://www.nssm.cc)就是这类在win下将普通程序运行成后台程序的软件\n\n## 服务安装：\n\n服务安装可以使用如下命令： `nssm install \u003cservicename\u003e`\n\n执行此命令后，会出现一个界面，基本上看着就知道怎么用了，大多数情况下，只需要填第一个界面的程序路径就可以了。\n\n其它界面的是高级参数的配置，可以根据需要自行选择。\n\n参数填完后执行\"install service\"按钮即可将服务安装到系统，可以使用系统的服务管理工具查看了。\n\n当然，如果要自动化安装，可以直接带上程序路径： `nssm install \u003cservicename\u003e \u003cprogram\u003e [\u003carguments\u003e]`\n\nNSSM本身win7及以上的系统基本都是支持的，我测试过win7，2008,2016系统，都是没有问题的，如果安装失败，请首先检查是否装了某国产管家或国产杀毒软件。\n\n安装完成后，服务还没有启动，需要通过下面的服务管理的命令启动服务。\n\n服务管理：\n\n服务管理主要有启动、停止和重启，其命令如下：\n\n启动服务：　nssm start \u003cservicename\u003e\n停止服务： nssm stop \u003cservicename\u003e\n重启服务:    nssm restart \u003cservicename\u003e\n当然，也可以使用系统自带的服务管理器操作和使用系统的命令。\n\n修改参数：\n\nNSSM安装的服务修改起来非常方便，命令如下：\n\n`nssm edit \u003cservicename\u003e`\n\n会自动启动操作界面，直接更改即可。\n\n## 服务删除：\n\n服务删除可以使用如下命令之一：\n\n```bash\nnssm remove \u003cservicename\u003e\nnssm remove \u003cservicename\u003e confirm\n```\n\n功能没有大的区别，后面的命令是自动确认的，没有交互界面。\n\n## 命令行：\n\n服务自动化需要使用更多的命令行，具体参看官方文档： Managing services from the command line\n如下是一个安装Jenkins服务的示例：\n\n```bash\nnssm install Jenkins %PROGRAMFILES%\\Java\\jre7\\bin\\java.exe\nnssm set Jenkins AppParameters -jar slave.jar -jnlpUrl https://jenkins/computer/%COMPUTERNAME%/slave-agent.jnlp -secret redacted\nnssm set Jenkins AppDirectory C:\\Jenkins\nnssm set Jenkins AppStdout C:\\Jenkins\\jenkins.log\nnssm set Jenkins AppStderr C:\\Jenkins\\jenkins.log\nnssm set Jenkins AppStopMethodSkip 6\nnssm set Jenkins AppStopMethodConsole 1000\nnssm set Jenkins AppThrottle 5000\nnssm start Jenkins\n```\n","cover":"","link":"nssm.html","preview":"\u003cp\u003ewin10下挂将exe应用运行成后台服务\u003c/p\u003e\n","title":"Run an exe app as service on win os"},{"content":"\n\n## 挂载EFI分区\n\n- Windows操作系统下面,以系统管理员身份打开cmd窗口,输入命令:\n\n```bash\nc:\\\u003ediskpart\nlist disk           # 磁盘列表\nselect disk n       # 选择EFI分区所在的磁盘，n为磁盘号\nlist partition      # 磁盘分区列表\nselect partition n  # 选择EFI分区，n为EFI分区号\nset id=\"ebd0a0a2-b9e5-4433-87c0-68b6b72699c7\"        # 设置为基本数据分区\nassign letter=X     # x为EFI分区盘符\nexit                                # 退出diskpart\nnotepad                                # 打开记事本程序，点击文件-\u003e打开，即可访问EFI分区\n```\n","cover":"","link":"mount_efi.html","preview":"\u003cp\u003ewin10下挂载EFI分区\u003c/p\u003e\n","title":"Mount the EFI partition on win 10"},{"content":"\n\n## Symptoms\n\nUnable to start MySQL/mysqld service. The following errors are foundin /var/log/mysqld.log:\n\n```\n[ERROR] InnoDB: innodb-page-size mismatch in tablespace ./phpmyadmin_rq_U9tqAuU26/pma_central_columns.ibd (table phpmyadmin_rq_U9tqAuU26/pma_central_columns)...\nInnoDB: Error: could not open single-table tablespace file ./phpmyadmin_rq_U9tqAuU26/pma_central_columns.ibd\n```\n\n## Cause\n\nCrash recovery of InnoDB cannot be finished because the table is corrupted during the recovery process.\n\n## Resolution\n\n- Log in to the server via SSH.\n- Move the file mentioned in the error message to the other directory:\n\n```\n$ mv /var/lib/mysql/phpmyadmin_rq_U9tqAuU26/pma_central_columns.ibd ~/\n```\n\n- Start the mysqld service (InnoDB recovery process will be executed automatically):\n\n```\n$ service mysqld start\n```\n","cover":"","link":"mysql_file_error.html","preview":"\u003cp\u003e一次mysql重启错误的解决.\u003c/p\u003e\n","title":"Mysql Error-could not open single-table tablespace file"},{"content":"\n\n\u003e 业务后端管理web端是jsp跑在tomcat上，处于安全需要配置了HTTP/2和客户端认证，以下是配置过程以供参考\n\n## 生成证书\n\n\u003e 系统在windows上，证书生成这里使用了jdk中的keytool工具，linux下可以使用openssl生成\n\n- 生成服务端证书库容器\n\n```bash\nkeytool -validity 36500 -genkey -v -alias server_test_trust -keyalg EC -keystore server.keystore -dname \"CN=192.168.1.10,OU=test,O=test,L=shanghai,ST=shanghai,c=cn\" -storepass test -keypass test\n```\n\n- 生成客户端证书库容器\n\n```bash\nkeytool -validity 36500 -genkey -v -alias server_test_trust -keyalg EC -keystore server_trust.keystore -dname \"CN=192.168.1.10,OU=test,O=test,L=shanghai,ST=shanghai,c=cn\" -storepass test -keypass test\n```\n\n- 生成客户端密钥对\n\n```bash\nkeytool -validity 36500 -genkeypair -v -alias client -keyalg EC -storetype PKCS12 -keystore client.p12 -dname \"CN=client,OU=test,O=test,L=shanghai,ST=shanghai,c=cn\" -storepass test -keypass test\n```\n\n- 导出客户端证书\n\n```bash\nkeytool -export -v -alias client -keystore client.p12 -storetype PKCS12 -storepass test -rfc -file client.cer\n```\n\n- 导入客户端证书到客户端证书库容器\n\n```bash\nkeytool -import -v -alias client -file client.cer -keystore server_trust.keystore -storepass test\n```\n\n## Tomcat9 HTTP/2 配置\n\n- 编辑conf/server.xml文件并加入以下配置项\n\n```xml\n    \u003cConnector\n           protocol=\"org.apache.coyote.http11.Http11NioProtocol\"\n           port=\"8443\" maxThreads=\"200\"\n           scheme=\"https\" secure=\"true\" SSLEnabled=\"true\"\n           keystoreFile=\"conf/server.keystore\" keystorePass=\"test\" // 服务端证书路径和密码\n           truststoreFile=\"conf/server_trust.keystore\" truststorePass=\"test\" // 客户端证书路径和密码\n           clientAuth=\"true\" // 开启客户端认证\n           sslProtocol=\"TLS1.2\" \u003e\n          \u003cUpgradeProtocol className=\"org.apache.coyote.http2.Http2Protocol\" /\u003e // 开启HTTP/2设置\n    \u003c/Connector\u003e\n```\n\n- 编辑conf/web.xml文件末尾加入以下配置可启用强制https\n\n```xml\n    \u003clogin-config\u003e  \n        \u003c!-- Authorization setting for SSL --\u003e  \n        \u003cauth-method\u003eCLIENT-CERT\u003c/auth-method\u003e  \n        \u003crealm-name\u003eClient Cert Users-only Area\u003c/realm-name\u003e  \n    \u003c/login-config\u003e  \n    \u003csecurity-constraint\u003e  \n        \u003c!-- Authorization setting for SSL --\u003e  \n        \u003cweb-resource-collection \u003e  \n            \u003cweb-resource-name \u003eSSL\u003c/web-resource-name\u003e  \n            \u003curl-pattern\u003e/*\u003c/url-pattern\u003e // 全站TLS\n        \u003c/web-resource-collection\u003e  \n        \u003cuser-data-constraint\u003e  \n            \u003ctransport-guarantee\u003eCONFIDENTIAL\u003c/transport-guarantee\u003e  \n        \u003c/user-data-constraint\u003e  \n    \u003c/security-constraint\u003e\n```\n\n\u003e Note: 客户端访问时先导入第一步生成的client.cer或client.p12，之后用浏览器访问时会要求选择证书.\n","cover":"","link":"tomcat_http2.html","preview":"\u003cp\u003eTomcat9下配置HTTP/2和客户端认证\u003c/p\u003e\n","title":"Tomcat9 http/2 configration and client authentication"},{"content":"\n\n\n# 使用vlmcsd部署kms server激活win$\n\n\u003e vlmcsd论坛源文地址：https://forums.mydigitallife.net/threads/emulated-kms-servers-on-non-windows-platforms.50234/\ngithub：https://github.com/Wind4/vlmcsd\n官方激活方法：http://wind4.github.io/vlmcsd/\n\n## 准备环境\n - Linux hosts \n - [vlmcsd package](https://github.com/Wind4/vlmcsd/releases)\n\n## 部署服务\n - 选择对应平台的执行文件: \n    依据CPU架构选择运行文件，vlmcsd或者vlmcsdmulti文件均可这里我以Linux/intel平台为例，选择了 vlmcsdmulti-x86-musl-static\n - 运行程序\n   ```bash\n    $ chmod +x  vlmcsdmulti-x86-musl-static\n    $ ./vlmcsdmulti-x86-musl-static\n    # 如果没有报错，就运行成功了，如果报错，检查端口占用\n    # centos开启端口对外访问\n    $ firewall-cmd --zone=public --add-port=1688/tcp --permanent\n    $ firewall-cmd reload\n    #本地端口连通性测试\n    $ telnet you.host.ip port\n   ```\n\n## 激活win$\n - 查看windows版本\n\n    ```\n    \u003e wmic os get caption\n    Caption\n    Microsoft Windows 10 企业版 2016 长期服务版\n    ```\n\n - 激活windows\n\n    ```\n    \u003e slmgr /skms you.host.ip\n    \u003e slmgr /ato\n    \u003e slmgr /xpr\n    ```\n\n - 查看激活信息\n\n    ```\n    \u003e slmgr /dlv\n    ```\n\n## 激活Office(OFFICE必须是VOL版本)\n\n- 进入office安装目录\n`cd \"C:\\Program Files\\Microsoft Office\\Office16\"`\n- 替换VOL的密钥\n`cscript ospp.vbs /inpkey:XQNVK-8JYDB-WJ9W3-YJ8YR-WFG99`\n- 注册kms服务器地址\n`cscript ospp.vbs /sethst:you-kms-server`\n- 执行激活\n`cscript ospp.vbs /act`\n- 查看状态\n`CSCRIPT OSPP.VBS /DSTATUS`\n\n# The VOL key list\n\n## Windows 10\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows 10 Core | TX9XD-98N7V-6WMQ6-BX7FG-H8Q99 |\n| Windows 10 Core N | 3KHY7-WNT83-DGQKR-F7HPR-844BM |\n| Windows 10 Core Country Specific | PVMJN-6DFY6-9CCP6-7BKTT-D3WVR |\n| Windows 10 Core Single Language | 7HNRX-D7KGG-3K4RQ-4WPJ4-YTDFH |\n| Windows 10 Professional | W269N-WFGWX-YVC9B-4J6C9-T83GX |\n| Windows 10 Professional N | MH37W-N47XK-V7XM9-C7227-GCQG9 |\n| Windows 10 Enterprise | NPPR9-FWDCX-D2C8J-H872K-2YT43 |\n| Windows 10 Enterprise N | DPH2V-TTNVB-4X9Q3-TJR4H-KHJW4 |\n| Windows 10 Education | NW6C2-QMPVW-D7KKK-3GKT6-VCFB2 |\n| Windows 10 Education N | 2WH4N-8QGBV-H22JP-CT43Q-MDWWJ |\n| Windows 10 Enterprise 2015 LTSB | WNMTR-4C88C-JK8YV-HQ7T2-76DF9 |\n| Windows 10 Enterprise 2015 LTSB N | 2F77B-TNFGY-69QQF-B8YKP-D69TJ |\n| Windows 10 Enterprise 2016 LTSB | DCPHK-NFMTC-H88MJ-PFHPY-QJ4BJ |\n| Windows 10 Enterprise 2016 LTSB N | QFFDN-GRT3P-VKWWX-X7T3R-8B639 |\n\n## Windows 8 / 8.1\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows 8 Professional | NG4HW-VH26C-733KW-K6F98-J8CK4 |\n| Windows 8 Professional N | XCVCF-2NXM9-723PB-MHCB7-2RYQQ |\n| Windows 8 Enterprise | 32JNW-9KQ84-P47T8-D8GGY-CWCK7 |\n| Windows 8 Enterprise N | JMNMF-RHW7P-DMY6X-RF3DR-X2BQT |\n| Windows Embedded 8 Industry Professional | RYXVT-BNQG7-VD29F-DBMRY-HT73M |\n| Windows Embedded 8 Industry Enterprise | NKB3R-R2F8T-3XCDP-7Q2KW-XWYQ2 |\n| Windows 8.1 Professional | GCRJD-8NW9H-F2CDX-CCM8D-9D6T9 |\n| Windows 8.1 Professional N | HMCNV-VVBFX-7HMBH-CTY9B-B4FXY |\n| Windows 8.1 Enterprise | MHF9N-XY6XB-WVXMC-BTDCT-MKKG7 |\n| Windows 8.1 Enterprise N | TT4HM-HN7YT-62K67-RGRQJ-JFFXW |\n| Windows Embedded 8.1 Industry Pro | NMMPB-38DD4-R2823-62W8D-VXKJB |\n| Windows Embedded 8.1 Industry Enterprise | FNFKF-PWTVT-9RC8H-32HB2-JB34X |\n\n## Windows 7\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows 7 Professional | FJ82H-XT6CR-J8D7P-XQJJ2-GPDD4 |\n| Windows 7 Professional N | MRPKT-YTG23-K7D7T-X2JMM-QY7MG |\n| Windows 7 Professional E | W82YF-2Q76Y-63HXB-FGJG9-GF7QX |\n| Windows 7 Enterprise | 33PXH-7Y6KF-2VJC9-XBBR8-HVTHH |\n| Windows 7 Enterprise N | YDRBP-3D83W-TY26F-D46B2-XCKRJ |\n| Windows 7 Enterprise E | C29WB-22CC8-VJ326-GHFJW-H9DH4 |\n\n## Windows Server 2019\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows Server 2019 Datacenter |WMDGN-G9PQG-XVVXX-R3X43-63DFG |\n| Windows Server 2019 Standard | N69G4-B89J2-4G8F4-WWYCC-J464C |\n| Windows Server 2019 Essentials| WVDHN-86M7X-466P6-VHXV7-YY726 |\n\n## Windows Server 2016\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows Server 2016 Datacenter | CB7KF-BWN84-R7R2Y-793K2-8XDDG |\n| Windows Server 2016 Standard | WC2BQ-8NRM3-FDDYY-2BFGV-KHKQY |\n| Windows Server 2016 Essentials | JCKRF-N37P4-C2D82-9YXRT-4M63B |\n\n## Windows Server 2012\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows Server 2012 | BN3D2-R7TKB-3YPBD-8DRP2-27GG4 |\n| Windows Server 2012 N | 8N2M2-HWPGY-7PGT9-HGDD8-GVGGY |\n| Windows Server 2012 Single Language | 2WN2H-YGCQR-KFX6K-CD6TF-84YXQ |\n| Windows Server 2012 Country Specific | 4K36P-JN4VD-GDC6V-KDT89-DYFKP |\n| Windows Server 2012 Server Standard | XC9B7-NBPP2-83J2H-RHMBY-92BT4 |\n| Windows Server 2012 MultiPoint Standard | HM7DN-YVMH3-46JC3-XYTG7-CYQJJ |\n| Windows Server 2012 MultiPoint Premium | XNH6W-2V9GX-RGJ4K-Y8X6F-QGJ2G |\n| Windows Server 2012 Datacenter | 48HP8-DN98B-MYWDG-T2DCC-8W83P |\n| Windows Server 2012 R2 Server Standard | D2N9P-3P6X9-2R39C-7RTCD-MDVJX |\n| Windows Server 2012 R2 Datacenter | W3GGN-FT8W3-Y4M27-J84CP-Q3VJ9 |\n| Windows Server 2012 R2 Essentials | KNC87-3J2TX-XB4WP-VCPJV-M4FWM |\n\n## Windows Server 2008\n\n| Operating system edition | KMS Client Setup Key |\n| --- | --- |\n| Windows Server 2008 Web | WYR28-R7TFJ-3X2YQ-YCY4H-M249D |\n| Windows Server 2008 Standard | TM24T-X9RMF-VWXK6-X8JC9-BFGM2 |\n| Windows Server 2008 Standard without Hyper-V | W7VD6-7JFBR-RX26B-YKQ3Y-6FFFJ |\n| Windows Server 2008 Enterprise | YQGMW-MPWTJ-34KDK-48M3W-X4Q6V |\n| Windows Server 2008 Enterprise without Hyper-V | 39BXF-X8Q23-P2WWT-38T2F-G3FPG |\n| Windows Server 2008 HPC | RCTX3-KWVHP-BR6TB-RB6DM-6X7HP |\n| Windows Server 2008 Datacenter | 7M67G-PC374-GR742-YH8V4-TCBY3 |\n| Windows Server 2008 Datacenter without Hyper-V | 22XQ2-VRXRG-P8D42-K34TD-G3QQC |\n| Windows Server 2008 for Itanium-Based Systems | 4DWFP-JF3DJ-B7DTH-78FJB-PDRHK |\n| Windows Server 2008 R2 Web | 6TPJF-RBVHG-WBW2R-86QPH-6RTM4 |\n| Windows Server 2008 R2 HPC edition | TT8MH-CG224-D3D7Q-498W2-9QCTX |\n| Windows Server 2008 R2 Standard | YC6KT-GKW9T-YTKYR-T4X34-R7VHC |\n| Windows Server 2008 R2 Enterprise | 489J6-VHDMP-X63PK-3K798-CPX3Y |\n| Windows Server 2008 R2 Datacenter | 74YFP-3QFB3-KQT8W-PMXWJ-7M648 |\n| Windows Server 2008 R2 for Itanium-based Systems | GT63C-RJFQ3-4GMB6-BRFB9-CB83V |\n\n## Office 2019\n\n| Product | GVLK |\n| --- | --- |\n| Office Professional Plus 2019 | NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP |\n| Office Standard 2019 | 6NWWJ-YQWMR-QKGCB-6TMB3-9D9HK |\n| Project Professional 2019 | B4NPR-3FKK7-T2MBV-FRQ4W-PKD2B |\n| Project Standard 2019 | C4F7P-NCP8C-6CQPT-MQHV9-JXD2M |\n| Visio Professional 2019 | 9BGNQ-K37YR-RQHF2-38RQ3-7VCBB |\n| Visio Standard 2019 | 7TQNQ-K3YQQ-3PFH7-CCPPM-X4VQ2 |\n| Access 2019 | 9N9PT-27V4Y-VJ2PD-YXFMF-YTFQT |\n| Excel 2019 | TMJWT-YYNMB-3BKTF-644FC-RVXBD |\n| Outlook 2019 | 7HD7K-N4PVK-BHBCQ-YWQRW-XW4VK |\n| PowerPoint 2019 | RRNCX-C64HY-W2MM7-MCH9G-TJHMQ |\n| Publisher 2019 | G2KWX-3NW6P-PY93R-JXK2T-C9Y9V |\n| Skype for Business 2019 | NCJ33-JHBBY-HTK98-MYCV8-HMKHJ |\n| Word 2019 | PBX3G-NWMT6-Q7XBW-PYJGG-WXD33 |\n\n## Office 2016\n\n| Product | GVLK |\n| --- | --- |\n| Office Professional Plus 2016 | XQNVK-8JYDB-WJ9W3-YJ8YR-WFG99 |\n| Office Standard 2016 | JNRGM-WHDWX-FJJG3-K47QV-DRTFM |\n| Project Professional 2016 | YG9NW-3K39V-2T3HJ-93F3Q-G83KT |\n| Project Standard 2016 | GNFHQ-F6YQM-KQDGJ-327XX-KQBVC |\n| Visio Professional 2016 | PD3PC-RHNGV-FXJ29-8JK7D-RJRJK |\n| Visio Standard 2016 | 7WHWN-4T7MP-G96JF-G33KR-W8GF4 |\n| Access 2016 | GNH9Y-D2J4T-FJHGG-QRVH7-QPFDW |\n| Excel 2016 | 9C2PK-NWTVB-JMPW8-BFT28-7FTBF |\n| OneNote 2016 | DR92N-9HTF2-97XKM-XW2WJ-XW3J6 |\n| Outlook 2016 | R69KK-NTPKF-7M3Q4-QYBHW-6MT9B |\n| PowerPoint 2016 | J7MQP-HNJ4Y-WJ7YM-PFYGF-BY6C6 |\n| Publisher 2016 | F47MM-N3XJP-TQXJ9-BP99D-8K837 |\n| Skype for Business 2016 | 869NQ-FJ69K-466HW-QYCP2-DDBV6 |\n| Word 2016 | WXY84-JN2Q9-RBCCQ-3Q3J3-3PFJ6 |\n\n## Office 2013\n\n| Product | GVLK |\n| --- | --- |\n| Office 2013 Professional Plus | YC7DK-G2NP3-2QQC3-J6H88-GVGXT |\n| Office 2013 Standard | KBKQT-2NMXY-JJWGP-M62JB-92CD4 |\n| Project 2013 Professional | FN8TT-7WMH6-2D4X9-M337T-2342K |\n| Project 2013 Standard | 6NTH3-CW976-3G3Y2-JK3TX-8QHTT |\n| Visio 2013 Professional | C2FG9-N6J68-H8BTJ-BW3QX-RM3B3 |\n| Visio 2013 Standard | J484Y-4NKBF-W2HMG-DBMJC-PGWR7 |\n| Access 2013 | NG2JY-H4JBT-HQXYP-78QH9-4JM2D |\n| Excel 2013 | VGPNG-Y7HQW-9RHP7-TKPV3-BG7GB |\n| InfoPath 2013 | DKT8B-N7VXH-D963P-Q4PHY-F8894 |\n| Lync 2013 | 2MG3G-3BNTT-3MFW9-KDQW3-TCK7R |\n| OneNote 2013 | TGN6P-8MMBC-37P2F-XHXXK-P34VW |\n| Outlook 2013 | QPN8Q-BJBTJ-334K3-93TGY-2PMBT |\n| PowerPoint 2013 | 4NT99-8RJFH-Q2VDH-KYG2C-4RD4F |\n| Publisher 2013 | PN2WF-29XG2-T9HJ7-JQPJR-FCXK4 |\n| Word 2013 | 6Q7VD-NX8JD-WJ2VH-88V73-4GBJ7 |\n\n## Office 2010\n\n| Product | GVLK |\n| --- | --- |\n| Office Professional Plus 2010 | VYBBJ-TRJPB-QFQRF-QFT4D-H3GVB |\n| Office Standard 2010 | V7QKV-4XVVR-XYV4D-F7DFM-8R6BM |\n| Access 2010 | V7Y44-9T38C-R2VJK-666HK-T7DDX |\n| Excel 2010 | H62QG-HXVKF-PP4HP-66KMR-CW9BM |\n| SharePoint Workspace 2010 | QYYW6-QP4CB-MBV6G-HYMCJ-4T3J4 |\n| InfoPath 2010 | K96W8-67RPQ-62T9Y-J8FQJ-BT37T |\n| OneNote 2010 | Q4Y4M-RHWJM-PY37F-MTKWH-D3XHX |\n| Outlook 2010 | 7YDC2-CWM8M-RRTJC-8MDVC-X3DWQ |\n| PowerPoint 2010 | RC8FX-88JRY-3PF7C-X8P67-P4VTT |\n| Project Professional 2010 | YGX6F-PGV49-PGW3J-9BTGG-VHKC6 |\n| Project Standard 2010 | 4HP3K-88W3F-W2K3D-6677X-F9PGB |\n| Publisher 2010 | BFK7F-9MYHM-V68C7-DRQ66-83YTP |\n| Word 2010 | HVHB3-C6FV7-KQX9W-YQG79-CRY7T |\n| Visio Standard 2010 | 767HD-QGMWX-8QTDB-9G3R2-KHFGJ |\n| Visio Professional 2010 | 7MCW8-VRQVK-G677T-PDJCM-Q8TCP |\n| Visio Premium 2010 | D9DWC-HPYVV-JGF4P-BTWQB-WX8BJ |\n\n","cover":"","link":"vlmcsd.html","preview":"\u003cp\u003e基于vlmcsd搭建的KMS服务器。KMS Emulator in C (currently runs on Linux including Android, FreeBSD, Solaris, Minix, Mac OS, iOS, Windows with or without Cygwin)\u003c/p\u003e\n","title":"Active win$ \u0026 office with vlmcsd"},{"content":"\n\n啥？ .user.ini 删不掉，是不是觉得自己真的不行了？\n```\n[root@localhost]# rm -rf .user.ini \nrm: cannot remove ‘.user.ini’: Operation not permitted\n```\n\n来看一下，该文件的属性\n```\n[root@Tech1024]# lsattr .user.ini \n----i----------- .user.ini\n```\n没错，文件被锁定了，不能修改，那么我们去除文件锁定属性\n```\n[root@Tech1024]# chattr -i .user.ini\n是不是可以删除了，你是不是喜极而泣，啊，自己终于又行了。\n```\n\u003e Note. lsattr和chattr真是对好基友\n","cover":"","link":"userinidelete.html","preview":"\u003cp\u003ePHP项目里有个神秘的.user.ini文件，用root都删不掉.\u003c/p\u003e\n","title":"root删不掉的.user.ini文件"},{"content":"\n\n### 安装方式：\n- Build from source\n\n```bash\n[root@localhost]# curl -SOL https://github.com/esnet/iperf/archive/3.6.tar.gz\n[root@localhost]# tar -xvf 3.6.tar.gz\n[root@localhost]# cd 3.6 \u0026\u0026 ./configure\n[root@localhost]# make\n[root@localhost]# make install\n```\n- Install from package manager (etc. apt,yum)\n\n```bash\nsudo apt install iperf3\nsudo yum install iperf3\n```\n\n### 使用方法：\n\n- 参数说明\n-s 以server模式启动，eg：iperf -s\n-c host以client模式启动，host是server端地址，eg：iperf -c 222.35.11.23\n\n- 通用参数\n-f [kmKM] 分别表示以Kbits, Mbits, KBytes, MBytes显示报告，默认以Mbits为单位,eg：`iperf -c 222.35.11.23 -f K`\n-i sec 以秒为单位显示报告间隔，eg：`iperf -c 222.35.11.23 -i 2`\n-l 缓冲区大小，默认是8KB,eg：iperf -c 222.35.11.23 -l 16\n-m 显示tcp最大mtu值\n-o 将报告和错误信息输出到文件 eg：`iperf -c 222.35.11.23 -o ciperflog.txt`\n-p 指定服务器端使用的端口或客户端所连接的端口eg：`iperf -s -p 9999;iperf -c 222.35.11.23 -p 9999`\n-u 使用udp协议\n-w 指定TCP窗口大小，默认是8KB\n-B 绑定一个主机地址或接口（当主机有多个地址或接口时使用该参数）\n-C 兼容旧版本（当server端和client端版本不一样时使用）\n-M 设定TCP数据包的最大mtu值\n-N 设定TCP不延时\n-V 传输ipv6数据包\n \n### 实例：\n- 服务端\n```\n[root@localhost bin]# iperf3 -s\n-----------------------------------------------------------\nServer listening on 5201\n-----------------------------------------------------------\n```\n- 客户端:\n```\n[root@localhost iperf-3.0.5]# iperf3 -c 192.168.0.1 --reverse --parallel 4\n```\n(192.168.0.1 服务器的IP地址，可设置为推流网卡IP)\n(--reverse表示服务端发送, 客户端接收;如果不加，就是客户端发送，服务端接收 --parallel 4表示4路并发流)\n\n\u003e issue: iperf3: error - unable to connect to server: No route to host  --- 这个错误要检查防火墙是否放行默认5201端口.\n\n\u003e issue: iperf3: error while loading shared libraries: libiperf.so.0: cannot open shared object file: No such file or directory\n问题原因：Linux系统中找不到libiperf.so.0 库文件，导致执行iperf3 –s时提示缺少相关lib库\n解决方法：通过find /usr/local/lib/ |grep iperf查找其他服务器上是否存在该lib库文件，查询到后拷贝libiperf.so.0库文件到此台服务器/usr/local/lib/目录下\n","cover":"","link":"iperf_useage.html","preview":"\u003cp\u003e用iperf测试内网连接速度.\u003c/p\u003e\n","title":"Use iperf to test Lan speeds..."},{"content":"\n\n## 使用systemd限制cpu占用\n\n\u003e 在基于 Linux-3.x 内核版本的很多发行版都提供了 Systemd 来管理系统和服务。同时也将 cgroup 功能加到了 slice, scope 和 service 三个单元中, 基于这些特性我们可以很方便的通过 systemd 来限制服务或者进程对系统资源的使用, 这在单主机多服务的场景下会很有用。下面则以 MySQL 服务为例介绍如何使用 systemd 限制资源的使用, 其它服务的限制和此等同。\n\n```bash\n# systemctl set-property mysql.service MemoryLimit=5G       # 5G 内存\n# systemctl set-property mysql.service CPUQuota=150%        # 150% cpu 使用率\n# systemctl set-property mysql.service BlockIOWeight=1000   # IO 权重\n```\n\n## 使用cpulimit程序限制cpu占用\n\n\u003e 对于没用使用Systemd来管理的发行版可用cpulimit这个程序来实现cpu占用的限制。\n\n### 安装方式：\n- Build from source\n\n```bash\ngit clone https://github.com/opsengine/cpulimit.git\ncd cpulimit\nmake\ncp src/cpulimit /usr/bin\n```\n\n- Install from package manager (etc. apt,yum)\n\n```bash\nsudo apt install cpulimit\nsudo yum install cpulimit\n```\n\n### 使用方法：\n输入cpulimit，查看使用方式\n#### 选项:\n* -l 0~400 限定CPU占据率0%~400%\n* -v 显现控制的统计信息\n* -z 当被控制的程式退出的时候，CPULimit程式也跟着退出\n* -i 同时限定被控程式的子进程\n* -p 被控程式的PID\n* -e 被控程式的程式称号\n \n举例，譬如要限定php-fpm进程的CPU使用率最高为50%，并显现控制信息\n```\ncpulimit -l 50 -i -v -e php-fpm\n```\n依据需要挑选能否进入 -z 参数\n\n如果需要后台执行，只需要在command前后进入`nohup……\u0026`，回车便可\n```\nnohup cpulimit -l 50 -e php-fpm -i -v \u0026\n```\n\n\n\n\u003e Note. 这个只能作为临时方法使用，还是要找出占用高的根本原因，从根本入手解决cpu占用过高的问题\n","cover":"","link":"cpulimit.html","preview":"\u003cp\u003e在linux下限制程序的cpu使用率。\u003c/p\u003e\n","title":"Limit cpu usage on linux"},{"content":"\n\n## 问题复现\n\n今天在服务器上执行bash时报错`‘/bin/sh: Syntax error: “(” unexpected`\n折腾了好久就是因为用的是linux将sh指向了dash而不是bash，so。。兼容就有问题了\n\n查看当前指向就是:\n\n```bash\necho $SHELL\n```\n一般在使用bash特性的脚本前写(推荐后面的写法):\n\n`#!/bin/bash` or `#!/usr/bin/env bash`\n\u003e Using #!/usr/bin/env NAME makes the shell search for the first match of NAME in the $PATH environment variable. It can be useful if you aren't aware of the absolute path or don't want to search for it.\n\n## 解决方案\n\n但是有时一些库就比较麻烦了,所以干脆直接修改指向\n\n```bash\ndpkg-reconfigure dash\n```\n\n弹出窗口选NO，关掉就OK了\n","cover":"","link":"bash_error.html","preview":"\u003cp\u003ebash另类报错\u003c/p\u003e\n","title":"bash ‘/bin/sh: Syntax error: “(” unexpected"},{"content":"\n\nWhen using the latest version of Debian 9 stable, even with all updates installed, by default, you can’t get a very recent kernel via the standard repositories in your package manager. While the idea of using Debian stable is to remain stable and rather conservative, there are several benefits with installing a newer kernel and in some cases it’s the only option to get the OS to support all your hardware. The risk and impact on stability is small and the process is rather simple.\n\nSome of the benefits are:\nSupport for previously unsupported hardware: every kernel release has a list of added drivers. Especially when you have recent hardware, a newer kernel could be required to fully support your video card for example.\nPerformance improvements and bug fixes: newer kernels often contain a lot of bug fixes, have new functions and performance tweaks. Here again, the most is to gain on newer hardware.\nNew kernel options and security fixes\nThe most recent (stable) kernel that is available at the moment of writing is version 4.12, released 27/07/2017. You can find a complete overview of changes in every kernel version at https://www.kernel.org/ or http://kernelnewbies.org/LinuxVersions\n\nThe latest version of the kernel available, at the time of writing, via the standard repositories for Debian 9 is/was. As you can see this kernel is quite recent but Stretch has just been released:\n\n```bash\nlyndon@debian:~$ cat /etc/debian_version\n9.1\nlyndon@debian:~$ uname -r\n4.9.0-3-amd64\n```\n\nThere are basically two options to install a newer kernel in Debian stretch. The first is the easiest and this is what I will explain in this post. The second is not so easy. It is simply to compile a newer kernel yourself. While compiling a kernel nowadays isn’t rocket science anymore, the first way is still preferable and will save you a lot of time because others have been through the second method and present you the result of their work :)\n\nInstalling a newer kernel in Debian Stretch\nThe easiest way to install a newer kernel in Debian, is to install it from the backports. Backports are packages taken from the next Debian release (called “testing”), adjusted and recompiled for usage on the stable release. For this post, I’m starting with a minimal install (system tools only), the only packages I added after finishing the installation were sudo and aptitude.\n\nIn order to install a kernel from the backports, we need to add the backports-repository for our Debian version to the apt-sources and update the list of available packages:\n\n```bash\nlyndon@debian:~$ echo \"deb http://ftp.debian.org/debian stretch-backports main\" | sudo tee -a /etc/apt/sources.list \u003e /dev/null\nlyndon@debian:~$ sudo apt-get update\n...\nReading package lists... Done\n```\n\nNow, you can browse the available kernels in the backports-rpository by adding -t wheezy-backports to your apt commands.:\n\n```bash\nlyndon@debian:~$ aptitude search linux-image\np   linux-image-4.11.0-0.bpo.1-amd64                                        - Linux 4.11 for 64-bit PCs\np   linux-image-4.11.0-0.bpo.1-amd64-dbg                                    - Debug symbols for linux-image-4.11.0-0.bpo.1-amd64\np   linux-image-4.11.0-0.bpo.1-rt-amd64                                     - Linux 4.11 for 64-bit PCs, PREEMPT_RT\np   linux-image-4.11.0-0.bpo.1-rt-amd64-dbg                                 - Debug symbols for linux-image-4.11.0-0.bpo.1-rt-amd64\ni A linux-image-4.9.0-3-amd64                                               - Linux 4.9 for 64-bit PCs\np   linux-image-4.9.0-3-amd64-dbg                                           - Debug symbols for linux-image-4.9.0-3-amd64\np   linux-image-4.9.0-3-rt-amd64                                            - Linux 4.9 for 64-bit PCs, PREEMPT_RT\np   linux-image-4.9.0-3-rt-amd64-dbg                                        - Debug symbols for linux-image-4.9.0-3-rt-amd64\ni   linux-image-amd64                                                       - Linux for 64-bit PCs (meta-package)\np   linux-image-amd64-dbg                                                   - Debugging symbols for Linux amd64 configuration (meta-package)\np   linux-image-rt-amd64                                                    - Linux for 64-bit PCs (meta-package), PREEMPT_RT\np   linux-image-rt-amd64-dbg                                                - Debugging symbols for Linux rt-amd64 configuration (meta-package)\n```\nBefore installing a newer kernel, it’s important that we upgrade installed packages to their newer versions in the backports-repo in order to be sure that dependencies will remain unbroken.\n\n`lyndon@debian:~$ sudo apt-get -t stretch-backports upgrade`\n\nAfter the upgrade, choose a kernel from the list and install it with apt. Most of the installations would want the kernel without suffix. The rt-suffix stands for realtime and is mostly interesting for embedded projects or machines that will drive industrial hardware. dbg stands for debugging.\n\n```bash\nlyndon@debian:~$ sudo apt-get -t stretch-backports install linux-image-4.11.0-0.bpo.1-amd64\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following additional packages will be installed:\n  firmware-linux-free irqbalance libglib2.0-0 libglib2.0-data libnuma1 shared-mime-info xdg-user-dirs\nSuggested packages:\n  linux-doc-4.11 debian-kernel-handbook\nThe following NEW packages will be installed:\n  firmware-linux-free irqbalance libglib2.0-0 libglib2.0-data libnuma1 linux-image-4.11.0-0.bpo.1-amd64 shared-mime-info xdg-user-dirs\n0 upgraded, 8 newly installed, 0 to remove and 2 not upgraded.\nNeed to get 45.4 MB of archives.\nAfter this operation, 211 MB of additional disk space will be used.\nDo you want to continue? [Y/n] y\n...\nrocessing triggers for initramfs-tools (0.130) ...\nupdate-initramfs: Generating /boot/initrd.img-4.11.0-0.bpo.1-amd64\nProcessing triggers for systemd (232-25+deb9u1) ...\nAfter the installation, reboot your system and select the newly installed kernel from the selection displayed in GRUB. Debian selects the new kernel by default.’\n```\n\nTo verify that the new kernel is used after booting:\n\n```bash\nlyndon@debian:~$ uname -r\n4.11.0-0.bpo.1-amd64\n```\n\nUninstalling unused kernels in Debian\nWhen everything works as expected, you can safely uninstall the older kernel in order to clean up your system and to free up some space in /boot\n\nTo check which kernels are currently installed:\n\n```bash\nlyndon@debian:~$ dpkg --get-selections|grep linux-image\nlinux-image-4.11.0-0.bpo.1-amd64\t\tinstall\nlinux-image-4.9.0-3-amd64\t\t\tinstall\nlinux-image-amd64\t\t\t\tinstall\n```\n\nUninstall the old one:\n\n```bash\nlyndon@debian:~$ sudo apt-get remove linux-image-4.9.0-3-amd64\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following packages will be REMOVED:\n  linux-image-4.9.0-3-amd64 linux-image-amd64\n0 upgraded, 0 newly installed, 2 to remove and 0 not upgraded.\nAfter this operation, 190 MB disk space will be freed.\nDo you want to continue? [Y/n] y\n(Reading database ... 31737 files and directories currently installed.)\nRemoving linux-image-amd64 (4.9+80+deb9u1) ...\nRemoving linux-image-4.9.0-3-amd64 (4.9.30-2+deb9u2) ...\nI: /vmlinuz.old is now a symlink to boot/vmlinuz-4.11.0-0.bpo.1-amd64\nI: /initrd.img.old is now a symlink to boot/initrd.img-4.11.0-0.bpo.1-amd64\n/etc/kernel/postrm.d/initramfs-tools:\nupdate-initramfs: Deleting /boot/initrd.img-4.9.0-3-amd64\n/etc/kernel/postrm.d/zz-update-grub:\nGenerating grub configuration file ...\nFound linux image: /boot/vmlinuz-4.11.0-0.bpo.1-amd64\nFound initrd image: /boot/initrd.img-4.11.0-0.bpo.1-amd64\ndone\n```\n\nThat should be all it takes in order to install a recent kernel and cleanup older kernels on a Debian system. Not so difficult as you thought probably :)\n","cover":"","link":"debain_upgrade_kernel.html","preview":"\u003cp\u003eDebian从backport升级到主线内核\u003c/p\u003e\n","title":"Debian从backport升级到主线内核"},{"content":"\n\n## 问题复现\n\n今天再升级ubuntu 16.04的内核时出现依赖libssl1.1.0问题\n\n```bash\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nYou might want to run 'apt-get -f install' to correct these:\nThe following packages have unmet dependencies:\n linux-headers-4.18.12-041812-generic : Depends: libssl1.1 (\u003e= 1.1.0) but it is not installable\nE: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).\n```\n\n## 解决方案\n\n单独下载安装一个libssl1.1_1.1.0g-2ubuntu4.1_amd64.deb文件然后再升级就可以了\n\n```bash\nwget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.0g-2ubuntu4_amd64.deb\nsudo dpkg -i libssl1.1_1.1.0g-2ubuntu4_amd64.deb\n```","cover":"","link":"libssl_error.html","preview":"\u003cp\u003eubuntu升级内核报libssl1.1依赖问题\u003c/p\u003e\n","title":"linux-headers-4.18.12-041812-generic : Depends: libssl1.1 (\u003e= 1.1.0) but it is not installable"},{"content":"\n\n\u003e 使用daemon.json配置docker remote API时出现以下错误:\n\n`Aug 09 10:38:49 node02 dockerd[1169]: unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives are specified both as a flag and in the configuration file: hosts: (from flag: [fd://], from file: [\nunix:///var/run/docker.sock tcp://0.0.0.0:2376])`\n\n## 解决方法：\n1. Use the command `sudo systemctl edit docker.service` to open an override file for docker.service in a text editor.\n\n2. Add or modify the following lines, substituting your own values.\n```\n[Service]\nExecStart=\nExecStart=/usr/bin/dockerd\n```\n3. Save the file.\n\n4. Reload the systemctl configuration.\n`$ sudo systemctl daemon-reload`\n\n5. Restart Docker.\n`$ sudo systemctl restart docker.service`\n\n6. Check to see whether the change was honored by reviewing the output of netstat to confirm dockerd is listening on the configured port.\n```\n$ sudo netstat -lntp | grep dockerd\ntcp        0      0 0.0.0.0:2376          0.0.0.0:*               LISTEN      3758/dockerd\n```\n\n","cover":"/images/docker.jpeg","link":"docker_issue.html","preview":"\u003cp\u003eDocker config remote API via daemon.json issue\u003c/p\u003e\n","title":"Docker config remote API via daemon.json issue"},{"content":"\n\n# 最近做 ci 用到需要获取最新的 git tag 信息，记录一下\n\n```bash\ngit fetch --tags origin # 拉取远程tag信息\ngit checkout `git describe --abbrev=0 --tags --match \"v[0-9]*\" $(git rev-list --tags --max-count=1)` #获取最新的tag，关键点是中间的正则匹配需要根据项目来\n```\n","cover":"","link":"git_tips_latest_tag.html","preview":"\u003cp\u003e获取最新的git tag.\u003c/p\u003e\n","title":"Get the latest git tag"},{"content":"\n\n\u003e Elasticsearch在生产环境中，需要做一系列的优化，以达到最佳的性能。虽然网上有些优化的建议和经验，但却不一定有效，下面就结合官网上的介绍和网上的一些指导加上自己在使用过程中的实际处理， 给出更加有说服力的一些意见和建议。\n官网的关于生产环境的部署的建议，`https://www.elastic.co/guide/en/elasticsearch/guide/current/deploy.html`\n\n1. 硬件：`https://www.elastic.co/guide/en/elasticsearch/guide/current/hardware.html`\n    - 内存：设置ES_HEAP_SIZE 为机器内存的1/2, 但不要超过32G.\n    - CPU：官网的意见是， 2~8核足够了， 从我的经验看， 一般是要超过2核的。我的机器用的是32核， top看的话， 也就用了2核多。当然核数多点也无妨的。\n    - 磁盘：首选是SSD + RAID0\n    - 网络：1 GbE, 10 GbE， 最好不要跨机房，容易造成网络延迟。\n\n2. JVM：`https://www.elastic.co/guide/en/elasticsearch/guide/current/_java_virtual_machine.html`\n除了ES_HEAP_SIZE， 不要擅自改变JVM 的参数， 只要使用ES本身的设置就好了。\n\n3. 重要的配置：`https://www.elastic.co/guide/en/elasticsearch/guide/current/important-configuration-changes.html`\nES通常是不需要调优处理的， 如果遇到性能问题， 最好的方法是安排更好的数据布局和增加节点数目。\n    1. discovery.zen.minimum_master_nodes:(number of master-eligible nodes / 2) + 1\n    防止一个集群里， 出现多个master，造成数据混乱。discovery.zen.minimum_master_nodes的数量应该是有资格成为master的node数量的1/2+1。\n    而且随着集群node数量的变化（主要是master-eligible\n    node数量的变化）， 需要动态的修改这个参数。可以使用如下的API动态修改。\n    ```\n    PUT /_cluster/settings\n    {\n        \"persistent\" : {\n            \"discovery.zen.minimum_master_nodes\" : 2\n        }\n    }\n    ```\n    2. 集群重启的设置：即集群停止工作后重新启动\n\n    为了防止集群重启过程中带来的数据重复备份及平衡转移等不必要的消耗， 可以通过gateway的设置来预防。\n        - gateway.recover_after_nodes: x 当有x个node上线之后， 开始集群的recovery \n        - \u001cgateway.expected_nodes: y\n        - gateway.recover_after_time: 5m 当有y个node加入集群 或者 重启5分钟之后，开始recovery \n    与此相对应的是 重启正在工作的集群中的某个node时的操作，\n    disable shard allocation， 防止ES对shards做rebalance\n    ```\n    PUT/_cluster/settings\n    {\n    \"transient\":{\n        \"cluster.routing.allocation.enable\":\"none\"\n    }\n    }\n    ```\n    shutdown single node\n    维护并重启该node reenable shard allocation\n    ```\n    PUT/_cluster/settings\n    {\n    \"transient\":{\n        \"cluster.routing.allocation.enable\":\"all\"\n    }\n    }\n    ```\n    平衡之后(status green),再对其它node重复上面的操作。\n\n4. 不需要动的配置：\n    1. GC的策略不要修改， 使用默认的就OK了。\n    2. threadpool的配置， 使用默认的就好了， 已经是经过验证的最优了。\n\n5. disable SWAP between memory and disk\n有3种策略：`https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html`，任意其一就行。\n我们的服务器，默认使用的vm.swappiness=0，可以通过sudo sysctl -a | grep swap验证。\n\n6. 句柄数和MMap\n设置最大句柄数为655360（我们的服务器是默认的），`sudo sysctl -a | grep fs.file-max`得到，可以通过 GET /_nodes/process 验证。\n设置MMap: `sysctl -w vm.max_map_count=262144`\n或者通过修改`/etc/sysctl.conf`文件中的`vm.max_map_count`永久改变(`sudo sysctl -p /etc/sysctl.conf`生效)。","cover":"","link":"es_issue.html","preview":"\u003cp\u003eElasticsearch的一些优化配置\u003c/p\u003e\n","title":"Elasticsearch的一些优化配置"},{"content":"\n\n## Vmware workstation 14 注册码\n\n###　最新VM14或更高的版本:\n```\nVF19H-8YY5L-48DQY-JEWNG-YPKF6\nVF3W2-AZF91-480VP-Z5YZZ-QURDD\nYV34A-D3Z4N-M817Y-Y6Y7V-M7H8F\nAC7TA-2WYD3-M814Y-UMQNX-XCHFA\n```\n### VM12或以下的版本：\n```\n5A02H-AU243-TZJ49-GTC7K-3C61N\nAG1N8-DZZ53-484QP-0YN5C-QQ0F2\nGG59U-DVZD5-M854Y-NYN7C-P3KW4\nAA39H-61W50-H8DCY-1MM79-N2RZ4\nUU148-6VF44-M80JY-YYMQV-WF89D\n```\n### Linux版本：\n```\n5F29M-48312-8ZDF9-A8A5K-2AM0Z\n5A02H-AU243-TZJ49-GTC7K-3C61\n```","cover":"","link":"somekeyarchive.html","preview":"\u003cp\u003e相关key存档\u003c/p\u003e\n","title":"存一些相关的key"},{"content":"\n\n## 使用brew安装jenkins\n`brew install jenkins`\n\n## 启动，停止，重启jenkins\n```bash\nbrew services start jenkins\nbrew services stop jenkins\nbrew services restart jenkins\n```\n## 外部访问jenkins\n\u003e 使用brew安装jenkins会避免很多其他安装方式产生的用户权限问题，但是会将httpListenAddress默认设置为127.0.0.1，我们需要提供外部访问有两种方法。\n\n1. 修改两个路径下的plist配置中的httpListenAddress后的ip地址为`0.0.0.0`并重启\n```\n～/Library/LaunchAgents/homebrew.mxcl.jenkins.plist\n/usr/local/opt/jenkins/homebrew.mxcl.jenkins.plist\n```\n2. 使用nginx等反向代理一下本地服务即可","cover":"","link":"brewjenkins.html","preview":"\u003cp\u003eMac下安装jenkins并配置服务启动\u003c/p\u003e\n","title":"Mac下安装jenkins并配置服务启动"},{"content":"\n\u003e CRUD是增删改查的简称，其中增删改都属于一种变动操作，而新增和删改分别属于两种不同类型的变动，如果以记账来类比，新增等同于多了一笔金额，而删改等同于减少了一笔金额。\n\n### 下面以文档的增删改查从记账角度看看如何理解:\n\n| 文档 | 记账 |\n| :----: | :----: |\n| 新增文档 | + 100 |\n| 修改文档 | -50 |\n| 删除文档 | -50 |\n\n文档的当前状态就是这些变动动作的累计，新增文档以后修改了这篇文档，最后又删除了这个文档，那么这个文档当前状态是没有了。而记账如果假设期初余额为零，存入了一笔100元，后来取出50，当再取出50时，这个账户当前余额就是0了。\n\n### 事件溯源EventSourcing与CRUD的区别就在于：\n\u003e ES中记录的是这三个变动，将这三个变动作为事件记录保存下来；而CRUD则是将这三个动作通过服务的增删改查方法调用SQL的insert/update/delete语句实现。\n\n- CRUD实现方式：\n\n| 文档 | 记账 |SQL实现 |\n| :----: | :----: | :----: |\n| 新增文档 | +100 | insert/update |\n| 修改文档 | -50 | update |\n| 删除文档 |-50 | delete/update |\n\n- 事件溯源EventSourcing实现方式：\n\n|文档|记账|ES实现|\n| :----: | :----: | :----: |\n|新增文档|+100|Event1|\n|修改文档|-50|Event2|\n|删除文档|-50|Event3|\n\n\n### ES实际记录的是包含Event1 Event2 Event3的集合\n当需要获得当前状态时，通过播放这些事件获得，比如账户当前余额是：`100 -50 -50=0`，文档当前状态通过遍历事件集合：`apply(event1) --\u003e apply(event2) ---\u003eapply(event3)` 计算以后的结果。 \n区块链实际是将ES的这些事件集合复制到每个机器上，同时将这些事件严格通过事件编号链接起来，事件之间就无法随意插入其他事件，保证事件链在分散式环境中的完整。\n区块链就是把`Event1 \u003c--- Event2 \u003c--- Event3`事件通过编号串联起来，每台机器上不但有一个完整的事件集合，而且这些事件通过编号串联起来如同一个链条，当有新的事件进来，首先找出事件链中最后的事件编号，然后靠算力算出新的事件编号:`Event1编号Hash \u003c--- Event2编号Hash ---\u003eEvent3编号Hash`\n**区块链其实是一种分布式的事件溯源ES**\n\n\u003e 总之，基于事件驱动的事件溯源ES是一种与传统CRUD完全不同的编程范式，更是一种新的区块链编程范式。通过这种事件驱动编程方式不但可以解决传统分布式事务的难题，而且可以提升了系统的扩展性和弹性。传统的CRUD方式虽然简单易用，但是非常依赖关系数据库技术，相信随着区块链技术的发展，传统CRUD编程将慢慢会淘汰，变成培训课堂上的练习入门技术。","cover":"","link":"blockchainvscurd.html","preview":"\u003cp\u003eCRUD是增删改查的简称，其中增删改都属于一种变动操作，而新增和删改分别属于两种不同类型的变动，如果以记账来类比，新增等同于多了一笔金额，而删改等同于减少了一笔金额。\u003c/p\u003e\n","title":"CRUD编程切换到事件溯源和区块链编程"},{"content":"\n\u003e 今天在更新系统包后在拉取docker image 时莫名出现'libz.so.1: version `ZLIB_1.2.5.1' not found'的错误，解决了顺便记录下。\n\n## docker pull 出错：\n```bash\ndeploy@DEV:~ $ docker pull redis:4-alpine\n4-alpine: Pulling from library/redis\nff3a5c916c92: Extracting [==================================================\u003e]  2.066MB/2.066MB\naae70a2e6027: Download complete\n87c655da471c: Download complete\n7f8fb829cc48: Download complete\nc72e0cff027d: Download complete\n276d6b52cd5b: Download complete\n4-alpine: Pulling from library/redis\nff3a5c916c92: Extracting [==================================================\u003e]  2.066MB/2.066MB\naae70a2e6027: Download complete\n87c655da471c: Download complete\n7f8fb829cc48: Download complete\nc72e0cff027d: Download complete\n276d6b52cd5b: Download complete\nfailed to register layer: Error processing tar file(exit status 1: /usr/bin/unpigz: /usr/local/lib/libz.so.1: version `ZLIB_1.2.5.1' not found (required by /usr/bin/unpigz)\n):\n```\n## 解决方法:\n```bash\nwget http://zlib.net/zlib-1.2.11.tar.gz\ntar zxf zlib-1.2.11.tar.gz\ncd zlib-1.2.11\n./configure\nmake \u0026\u0026 make install\n```\n","cover":"","link":"zlib-issue.html","preview":"","title":"Docker拉镜像时出version `ZLIB_1.2.5.1' not found的解决方法"},{"content":"\n\n# [原文链接](https://www.elastic.co/blog/hot-warm-architecture-in-elasticsearch-5-x)\n\n# Elasticsearch 5.x 版本中的冷热节点架构\n当Elasticsearch用于大量实时数据分析的场景时，我们推荐使用基于时间的索引然后使用三种不同类型的节点（Master, Hot-Node 和 Warm-Node）进行结构分层，这就是所谓的\"Hot-Warm\"架构。每种节点有自己的任务，下面会进行介绍。\n\n### Master 节点\n我们推荐每个集群运行三个专用的Master节点来提供最好的弹性。使用时，你还需要将 discovery.zen.minimum_master_nodes setting 参数设置为2，以免出现脑裂的情况。用三个专用的Master节点，专门负责处理集群的管理以及加强状态的整体稳定性。因为这三个Master节点不包含数据也不会实际参与搜索以及索引操作，在JVM上它们不用做相同的事，例如繁重的索引或者耗时，资源耗费很大的搜索。因此不太可能会因为垃圾回收而导致停顿。因此，Master节点的CPU，内存以及磁盘配置可以比Data节点少很多的。\n\n### Hot 节点\n指定的Data节点会完成集群内所有的索引工作。这些节点同时还会保存近期的一些频繁被查询的索引。由于进行索引非常耗费CPU和IO，因此这些节点的服务器需要强大的SSD存储来支撑。我们推荐部署最小化的三个Hot节点来保证高可用性。根据近期需要收集以及查询的数据量，可以增加服务器数量来获得想要的性能。\n\n### Warm 节点\n这种类型的节点是为了处理大量的而且不经常访问的只读索引而设计的。由于这些索引是只读的，Warm节点倾向于挂载大量磁盘（普通磁盘）来替代SSD。跟Hot节点一样，我们建议部署最小化的三个Warn节点来保证高可用性。然后跟之前一样地，数据量大的话还是需要额外的节点来达到性能要求。而且还需注意的是CPU和内存配置跟Hot节点保持一致。通过测试一些类似生产环境中耗费比较大的查询可以确认这些东西。\n\nElasticsearch集群需要知道哪些服务器有Hot节点以及哪些服务器有Warm节点。这个可以通过分配所需的[属性](https://www.elastic.co/guide/en/elasticsearch/reference/5.1/allocation-awareness.html#forced-awareness)给服务器来实现。\n\n例如，你可以在 elasticsearch.yml 这个配置文件中通过 node.attr.box_type: hot 把节点设置为hot，或者你也可以在启动节点时使用 ./bin/elasticsearch -Enode.attr.box_type=hot 参数指定。\n\nbox_type 这个属性字段你完全可以自定义成你要的。这些自定义的值用于告知 Elasticsearch 从哪里分配索引。\n\n通过以下配置创建索引，我们可以确保今天的索引落在使用SSD的Hot节点上：\n```\nPUT /logs_2016-12-26\n{\n  \"settings\": {\n    \"index.routing.allocation.require.box_type\": \"hot\"\n  }\n}\n```\n\n过几天之后如果索引不再需要性能好的硬件时，我们可以将这些节点标记成Warm属性，更新索引配置如下：\n```\nPUT /logs_2016-12-26/_settings \n{ \n  \"settings\": { \n    \"index.routing.allocation.require.box_type\": \"warm\"\n  } \n}\n\n```\n\n那么现在我们可以使用logstash或者beats来实现：\n如果索引模板在logstash或者beats中管理，那么索引模板需要做一些更新，包括分配过滤器。\"index.routing.allocation.require.box_type\" : \"hot\" 这个配置会使新的索引创建在Hot节点上。\n例如：\n```\n{\n  \"template\" : \"indexname-*\",\n  \"version\" : 50001,\n  \"settings\" : {\n             \"index.routing.allocation.require.box_type\": \"hot\"\n ...\n```\n另外一个策略是给集群中的所有索引添加一个普通模板，在Hot节点上 \"template\": \"*\" 模板可以生成新的索引。\n例如：\n```\n{\n  \"template\" : \"*\",\n  \"version\" : 50001,\n  \"settings\" : {\n           \"index.routing.allocation.require.box_type\": \"hot\"\n ...\n```\n\n当你确认一个所以不再承担写入以及不需要频繁搜索时，它可以从Hot节点中合并到Warm节点。这个可以通过更新它的索引配置：\"index.routing.allocation.require.box_type\" : \"warm\" 轻而易举地完成这个操作。\nElasticsearch会自动合并索引到Warm节点。\n\n最后，我们还可以在所有Warm数据节点上开启更好的压缩配置，在elasticsearch.yml配置文件中的 index.codec: best_compression 的这个配置项可以配置。\n当数据移动到Warm节点后，我们可以调用 _forcemerge API 来合并分段: 虽然可以节约内存, 磁盘空间以及更少的文件句柄, 也有使用新的 best_compression 编码进行索引重写所带来的副作用. \n\n当还需要分配到 strong boxes 时强制合并索引不是什么好办法，这些节点上的进程会优先进行I/O操作然后影响到正在进行索引的当天日志。但是 medium boxes 则不会有太多操作，所以这是安全的。\n现在我们已经看到如何手动修改索引的分片分配，接下来让我们来看下如何使用[Curator](https://www.elastic.co/guide/en/elasticsearch/client/curator/current/installation.html)这个工具来自动处理这些事情。\n下面的例子中我们使用curator 4.2从Hot节点移动三天前的索引到Warm节点：\n```\nactions:\n  1:\n    action: allocation\n    description: \"Apply shard allocation filtering rules to the specified indices\"\n    options:\n      key: box_type\n      value: warm\n      allocation_type: require\n      wait_for_completion: true\n      timeout_override:\n      continue_if_exception: false\n      disable_action: false\n    filters:\n    - filtertype: pattern\n      kind: prefix\n      value: logstash-\n    - filtertype: age\n      source: name\n      direction: older\n      timestring: '%Y.%m.%d'\n      unit: days\n      unit_count: 3\n```\n最后我们可以使用curator来强制合并索引。执行优化之前要确保等待足够长的时间进行索引重新分配。你可以设置操作1中 wait_for_completion，或者修改操作2中的 unit_count 来选择4天前的索引.这样就有机会在强制合并之前完全合并。\n```\n2:\n    action: forcemerge\n    description: \"Perform a forceMerge on selected indices to 'max_num_segments' per shard\"\n    options:\n      max_num_segments: 1\n      delay:\n      timeout_override: 21600 \n      continue_if_exception: false\n      disable_action: false\n    filters:\n    - filtertype: pattern\n      kind: prefix\n      value: logstash-\n    - filtertype: age\n      source: name\n      direction: older\n      timestring: '%Y.%m.%d'\n      unit: days\n      unit_count: 3\n```\n\u003e 注意 timeout_override 要比默认值 21600 秒大，不过它可能会更快或者慢一点，这取决于你的配置。\n从Elasticsearch 5.0开始我们还可以使用 Rollover 和 shrink api 来减少分片数量，可以以更简单高效的方式来管理基于时间的索引。你可以在这个[博客](https://www.elastic.co/blog/managing-time-based-indices-efficiently)中找到更多细节。\n","cover":"/images/zsh.png","link":"hot-warm-architecture-in-elasticsearch-5-x-in-chinese.html","preview":"","title":"Hot warm architecture in elasticsearch"},{"content":"\n在Linux系统操作中，通常在设置账户的时候是不会设置有效期的，主要在企业中会使用到，当Linux账户过期的时候要怎么延长有效期呢？下面就给大家介绍下Linux账户过期的解决方法，一起来学习下吧。\n\n1. 在添加用户时\n`useradd user -e 01/01/2018`\n\n2. 修改用户属性\n`usermod -e 01/01/2018 user`\n\n3. 直接调整\u0008时间\n`chage -E 01/01/2018 user`\n\n### 查看用户过期时间\n`chage -l user`","cover":"/images/zsh.png","link":"linux_user_expire.html","preview":"","title":"Linux user expired"},{"content":"\nRedis 启动时会遇到以下警告，对于强迫症患者实在是不能忍，下面给出消除方法.\n\n```\n26069:M 08 Aug 17:06:58.858 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n26069:M 08 Aug 17:06:58.859 # Server started, Redis version 3.0.7\n26069:M 08 Aug 17:06:58.859 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n26069:M 08 Aug 17:06:58.859 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n26069:M 08 Aug 17:06:58.978 * DB loaded from disk: 0.119 seconds\n```\n\n* 分别执行如下语句：\n```\necho 511 \u003e /proc/sys/net/core/somaxconn\necho \"vm.overcommit_memory = 1\" \u003e\u003e /etc/sysctl.conf\nsysctl vm.overcommit_memory=1\necho never \u003e /sys/kernel/mm/transparent_hugepage/enabled\n```\n* \u0008保证重启后也\u0008生效需要再在/etc/rc.local的最后添加\necho never \u003e /sys/kernel/mm/transparent_hugepage/enabled","cover":"/images/zsh.png","link":"redis-warning.html","preview":"","title":"Redis startup warning"},{"content":"\n\u003e 使用NVM来管理node的版本，并使用国内镜像安装\n\n![Node](/images/nodejs.png)\n## 安装[NVM](https://github.com/creationix/nvm)\n\n### 从GITHUB获取最新链接\n* Use curl install\n```bash\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n```\n* or use wget\n```bash\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.2/install.sh | bash\n```\n\n## 设置环境变量使用\u0008国内node镜像\n* Set nvm mirrors\n```bash\n$ vim ~/.bashrc\n# set nodejs env\nexport NVM_NODEJS_ORG_MIRROR=http://npm.taobao.org/mirrors/node\n```\n* Take it effect\n```bash\n$ source ~/.bashrc\n```\n* Set npm mirrors\n```bash\n$ npm config set registry https://registry.npm.taobao.org\n```\n","cover":"/images/nodejs.png","link":"nvm-install.html","preview":"","title":"Use nvm to manage node"},{"content":"\n\u003e 又是cors跨域…cors是啥？就是跨域请求。下面给出nginx cors的相关配置。\n\n* 允许哪个域名来访问资源\n```\nadd_header 'Access-Control-Allow-Origin' \"$http_origin\";\n```\n* 请求的返回内容里包含cookies\n```\nadd_header 'Access-Control-Allow-Credentials' 'true';\n```\n* 允许请求的method \n```\nadd_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n```\nnginx conf example: \n```\nlocation / {\n       if ($request_method = 'OPTIONS') {\n                add_header 'Access-Control-Allow-Origin' \"$http_origin\";\n                add_header 'Access-Control-Allow-Methods' 'PUT, DELETE, GET, POST, OPTIONS';\n                add_header 'Access-Control-Allow-Headers' 'reqid, nid, host, x-real-ip, x-forwarded-ip, event-type, event-id, accept, content-type';\n                add_header 'Access-Control-Max-Age' 1728000;\n                return 204;\n             }\n        add_header 'Access-Control-Allow-Origin' \"$http_origin\";\n        add_header 'Access-Control-Allow-Credentials' 'true';\n        add_header 'Access-Control-Allow-Methods' 'PUT, GET, POST, OPTIONS, DELETE';\n        add_header 'Access-Control-Allow-Headers' 'reqid, nid, host, x-real-ip, x-forwarded-ip, event-type, event-id, accept, content-type';\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_connect_timeout 120s;\n        proxy_send_timeout 120s;\n        proxy_read_timeout 120s;\n        proxy_buffering    on;\n        proxy_buffer_size 64k;\n        proxy_buffers  4 32k;\n        proxy_busy_buffers_size 64k;\n        proxy_pass http://server;\n      }\n```","cover":"/images/zsh.png","link":"nginxcrossite.html","preview":"","title":"Nginx cros site"},{"content":"\n\u003e scp命令可以在linux之间复制文件和目录 \n\n### 命令基本格式\n`scp [option] file_source file_target`\n\n#### 从本地复制到远程\n```\nscp local_file remote_username@remote_ip:remote_folder\nscp local_file remote_username@remote_ip:remote_file\nscp local_file remote_ip:remote_folder\nscp local_file remote_ip:remote_file\n```\n第1,2个指定了用户名，命令执行后需要再输入密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名；\n第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名；\n```\nscp /home/space/music/1.mp3 root@www.cumt.edu.cn:/home/root/others/music \nscp /home/space/music/1.mp3 root@www.cumt.edu.cn:/home/root/others/music/001.mp3 \nscp /home/space/music/1.mp3 www.cumt.edu.cn:/home/root/others/music \nscp /home/space/music/1.mp3 www.cumt.edu.cn:/home/root/others/music/001.mp3 \n```\n* 复制目录： \n```\nscp -r local_folder remote_username@remote_ip:remote_folder \nscp -r local_folder remote_ip:remote_folder \n```\n第1个指定了用户名，命令执行后需要再输入密码； \n第2个没有指定用户名，命令执行后需要输入用户名和密码； \n```\nscp -r /home/space/music/ root@www.cumt.edu.cn:/home/root/others/ \nscp -r /home/space/music/ www.cumt.edu.cn:/home/root/others/ \n```\n#### 从远程复制到本地\n从远程复制到本地, 只要将从本地复制到远程的命令的后2个参数调换顺序即可；\n```\nscp root@www.cumt.edu.cn:/home/root/others/music /home/space/music/1.mp3 \nscp -r www.cumt.edu.cn:/home/root/others/ /home/space/music/\n```\n最简单的应用如下: `scp user@IP:filename remoteuser@IP:filename`\n\n*可能有用的几个参数: *\n+ -v 和大多数linux命令中的-v意思一样, 用来显示进度.可以用来查看连接, 认证或是配置错误.\n+ -C 使能压缩选项.\n+ -P 选择端口. 注意-p已经被rcp使用.\n+ -4 强行使用IPV4地址.\n+ -6 强行使用IPV6地址.\n\n\n*注意两点*\n1. 如果远程服务器防火墙有特殊限制，scp要走特殊端口，命令格式如下: \n\n`scp -p 4588 remote@www.abc.com:/usr/local/sin.sh /home/administrator`\n\n2. 使用scp要注意所使用的用户是否具有可读取远程服务器相应文件的权限。\n","cover":"/images/zsh.png","link":"scp.html","preview":"","title":"使用scp再linux间拷贝文件和目录"},{"content":"\n\u003e 最近，Google 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，最新的 4.11 版内核已经用上了该算法。根据以往的传统，Google 总是先在自家的生产环境上线运用后，才会将代码开源，此次也不例外。\n根据实地测试，在部署了最新版内核并开启了 TCP BBR 的机器上，网速甚至可以提升好几个数量级。\n\n## 手动安装：\nUbuntu系统下载对应版本和架构（amd64）的\u0010[内核镜像](http://kernel.ubuntu.com/~kernel-ppa/mainline/)（linux-image.+_amd64.deb）、内核头文件（linux-headers.+.deb），然后用 dpkg 安装并重启系统。\n重启进入4.11.x 的内核之后，执行如下命令开启 BBR：\n```\nsudo bash -c 'echo \"net.core.default_qdisc=fq\" \u003e\u003e /etc/sysctl.conf'\nsudo bash -c 'echo \"net.ipv4.tcp_congestion_control=bbr\" \u003e\u003e /etc/sysctl.conf'\nsudo sysctl -p\n```\n执行如下命令确认 BBR 成功开启，两个命令的预期输出都是 1：\n```\nsysctl net.ipv4.tcp_available_congestion_control | grep bbr | wc -l\nlsmod | grep tcp_bbr | wc -l\n```\n开启 BBR 的效果还是蛮明显的，浏览器关闭缓存访问博客，完整加载耗时缩短将近一半。\n\n## 懒人一键安装:\n```\nwget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh\nchmod +x bbr.sh\n./bbr.sh\n```\n","cover":"/images/bbr.png","link":"bbr.html","preview":"","title":"给Linux开启BBR"},{"content":"\n\u003e exfat分区由于各种原因有些不稳定，下面的方法仅供参考\n\n## Windows 下：\n不要用磁盘修复，会提示必须先格式化。\n管理员身份打开命令行（Cmd），输入以下代码：\n```\nchkdsk {drive}: /f\n```\n例如：chkdsk E: /f 表示修复E 盘\n\n## Mac 下：\n过程略复杂，首先尝试用自带的磁盘工具（Disk Utility）修复，如果不成功再执行下面的步骤。\n打开终端，输入：\n```\nsudo fsck_exfat -d diskXsX\n```\n这里diskXsX 表示要修复的分区，比如disk0s4\n会出现一大堆文件列表，最后提示：\n```\nMain boot region needs to be updated. Yes/No?\n```\n输入Yes 即可。\n最后再回到Disk Utility 去重新修复分区，这次就会成功了。","cover":"","link":"exfat_fix.html","preview":"","title":"Win/Mac 下修复exFAT 分区"},{"content":"\n\u003e 一首最近很流行的诗与大家共勉\n\n```\n纽约时间比加州时间早三个小时，\n\nNew York is 3 hours ahead of California,\n\n但加州时间并没有变慢。\n\nbut it does not make California slow.\n\n有人22岁就毕业了，\n\nSomeone graduated at the age of 22,\n\n但等了五年才找到好的工作！\n\nbut waited 5 years before securing a good job!\n\n有人25岁就当上CEO，\n\nSomeone became a CEO at 25,\n\n却在50岁去世。\n\nand died at 50.\n\n也有人迟到50岁才当上CEO，\n\nWhile another became a CEO at 50,\n\n然后活到90岁。\n\nand lived to 90 years.\n\n有人依然单身，\n\nSomeone is still single,\n\n同时也有人已婚。\n\nwhile someone else got married.\n\n奥巴马55岁就退休，\n\nObama retires at 55,\n\n川普70岁才开始当总统。\n\nbut Trump starts at 70.\n\n世上每个人本来就有自己的发展时区。\n\nAbsolutely everyone in this world works based on their Time Zone.\n\n身边有些人看似走在你前面，\n\nPeople around you might seem to go ahead of you,\n\n也有人看似走在你后面。\n\nsome might seem to be behind you.\n\n但其实每个人在自己的时区有自己的步程。\n\nBut everyone is running their own RACE, in their own TIME.\n\n不用嫉妒或嘲笑他们。\n\nDon’t envy them or mock them.\n\n他们都在自己的时区里，你也是！\n\nThey are in their TIME ZONE, and you are in yours!\n\n生命就是等待正确的行动时机。\n\nLife is about waiting for the right moment to act.\n\n所以，放轻松。\n\nSo, RELAX.\n\n你没有落后。\n\nYou’re not LATE.\n\n你没有领先。\n\nYou’re not EARLY.\n\n在命运为你安排的属于自己的时区里，一切都准时。\n\nYou are very much ON TIME, and in your TIME ZONE Destiny set up for you.\n```\n","cover":"/images/zsh.png","link":"poem_with.html","preview":"","title":"一首最近很流行的诗"},{"content":"\n之前的mac os中添加私钥到keychain即可生效，重启后也生效，现在到了12.2后apple做了更新，重启后失效了。\n\u003e在官网找到了解决办法如下，在.ssh/config中配置\n\n```\nHost test\n  HostName test.eg.com\n  port 55522\n  user deploy\n  IdentityFile ~/.ssh/id_rsa\n  UseKeychain yes     # 使用keychain \n  AddKeysToAgent yes  # ssh-agent自动加载\n```\n","cover":"/images/zsh.png","link":"openssh_config_for_mac12.html","preview":"","title":"OpenSSH config for mac 10.12.2"},{"content":"\n\u003e 在docker安装完毕后，需要进行必要的设置以便更好的为我们服务\n\n## 安装Docker\n推荐使用阿里云的国内源进行安装，原因你们知道的GFW，另外就是很快很方便[传送门](http://mirrors.aliyun.com/help/docker-engine)\n\n## 消除\"WARNING: No swap limit support\"\n这个默认官方给予解决方法了:[链接](https://docs.docker.com/engine/installation/linux/ubuntu/)\n```\nWhen users run Docker, they may see these messages when working with an image:\n\nWARNING: Your kernel does not support cgroup swap limit. WARNING: Your\nkernel does not support swap limit capabilities. Limitation discarded.\nTo prevent these messages, enable memory and swap accounting on your system. To enable these on system using GNU GRUB (GNU GRand Unified Bootloader), do the following.\n\nLog into Ubuntu as a user with sudo privileges.\n\nEdit the /etc/default/grub file.\n\nSet the GRUB_CMDLINE_LINUX value as follows:\n\nGRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\"\nSave and close the file.\n\nUpdate GRUB.\n\n$ sudo update-grub\nReboot your system.\n```\n\n## 配置加速器，使用overlay2，启用Live Restore\n以ubuntu为例，其他发行版请自行查看[官方文档](https://docs.docker.com)\n\u003e 使用overlay需要内核版本在3.18以上，并且在内核中已启用[传送门](http://snakeliwei.github.io/2015/12/03/Docker-overlay/)。启用Live Restore后在更新docker daemon时不影响已启动的容器。\n\n- Docker客户端版本大于1.10的用户\n修改daemon配置文件/etc/docker/daemon.json：\n\n```bash\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json \u003c\u003c-'EOF'\n{\n  \"registry-mirrors\": [\"https://knb1nxmo.mirror.aliyuncs.com\"],\n  \"storage-driver\": \"overlay2\", //使用第二版驱动\n  \"live-restore\": true\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n- Docker客户的版本小于等于1.10的用户或者想配置启动参数，可以使用下面的命令将配置添加到docker daemon的启动参数中。\n\n1. Ubuntu 12.04 14.04的用户\n\n```bash\necho \"DOCKER_OPTS=\\\"\\$DOCKER_OPTS --registry-mirror=https://knb1nxmo.mirror.aliyuncs.com -s overlay --live-restore=true \\\"\" | sudo tee -a /etc/default/docker\nsudo service docker restart\n```\n\n2. Ubuntu 15.04 16.04的用户\n\n```bash\nsudo mkdir -p /etc/systemd/system/docker.service.d\nsudo tee /etc/systemd/system/docker.service.d/mirror.conf \u003c\u003c-'EOF'\n[Service]\nExecStart=/usr/bin/docker daemon -H fd:// --registry-mirror=https://knb1nxmo.mirror.aliyuncs.com -s overlay --live-restore=true\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n","cover":"/images/zsh.png","link":"after_docker_install.html","preview":"","title":"After Docker Install"},{"content":"\n\u003e在用 ssh-keygen 生成密钥对时，通常会面临是使用RSA还是DSA的选择：RSA or DSA, this is a question!\n\n## 原理与安全性：\nRSA 与 DSA 都是非对称加密算法。其中RSA的安全性是基于极其困难的大整数的分解（两个素数的乘积）；DSA 的安全性是基于整数有限域离散对数难题。基本上可以认为相同密钥长度的 RSA 算法与 DSA 算法安全性相当。\n有点要注意，RSA 的安全性依赖于大数分解，但是否等同于大数分解一直未能得到理论上的证明，因为没有证明破解 RSA 就一定需要作大数分解。不过也不必太过担心，RSA 从诞生以来，经历了各种攻击，至今未被完全攻破（依靠暴力破解，小于1024位密钥长度的 RSA 有被攻破的记录，但未从算法上被攻破）。\n\n## 用途：\nDSA 只能用于数字签名，而无法用于加密（某些扩展可以支持加密）；RSA 即可作为数字签名，也可以作为加密算法。不过作为加密使用的 RSA 有着随密钥长度增加，性能急剧下降的问题。\n\n## 性能：\n相同密钥长度下，DSA 做签名时速度更快，但做签名验证时速度较慢，一般情况验证签名的次数多于签名的次数。\n相同密钥长度下，DSA （在扩展支持下）解密密文更快，而加密更慢；RSA 正好反过来，一般来说解密次数多于加密次数。不过由于非对称加密算法的先天性能问题，两者都不是加密的好选择。\n\n## 业界支持：\n在业界支持方面，RSA 显然是赢家。RSA 具有更为广泛的部署与支持。\n\n## 使用 ssh-keygen 时的选择\n上面说了那么多，可以看到RSA 与 DSA 各有优缺点。回到开头的问题，在使用 ssh-keygen 时，RSA 与 DSA到底选哪个？ 比较有意思的是，这个问题最终答案与上面那些优缺点无关。虽然理论上可以生成更长长度的 DSA 密钥 （NIST FIPS 186-3），但ssh-keygen在生成 DSA 密钥时，其长度只能为1024位（基于NIST FIPS 186-2）；而 ssh-keygen 在 RSA 的密钥长度上没有限制。\n由于小于1024位密钥长度的 RSA 已经有被攻破的记录，所以说现在：RSA 2048 位密钥是更好的选择。\n\n## 其它选择：\nRSA 与 DSA 各有优缺点，那有没一个更好的选择呢？答案是肯定的，ECC（Elliptic Curves Cryptography）：椭圆曲线算法。\nECC 与 RSA 相比，有以下的优点：\n1. 相同密钥长度下，安全性能更高，如160位ECC已经与1024位RSA、DSA有相同的安全强度。\n2. 计算量小，处理速度快，在私钥的处理速度上（解密和签名），ECC远 比RSA、DSA快得多。\n3. 存储空间占用小 ECC的密钥尺寸和系统参数与RSA、DSA相比要小得多， 所以占用的存储空间小得多。\n4. 带宽要求低使得ECC具有广泛得应用前景。\n\n\u003e在 ssh-keygen 中，ECC 算法的相应参数是 “-t ecdsa”。可惜的是由于椭圆曲线算法只有在较新版本的 openssl 与 ssh-keygen 中才被支持，而无法得到普遍使用而去完全替代 RSA/DSA。不过由于椭圆曲线算法的优点，使其取代 RSA/DSA 而成为新一代通用的非对称加密算法成为可能，至少 SET 协议的制定者们已经把它作为下一代 SET 协议中缺省的公钥密码算法了。\n","cover":"/images/zsh.png","link":"ssh-keygen.html","preview":"","title":"SSH 密钥类型的的选择（RSA， DSA or Other"},{"content":"\n\u003e生产系统上通常不让\u0008随便启用\u0008可写权限，这里给出\u0008只读用户创建方法\n\n\n### 创建一个用户名为readonly密码为ropass的用户\n```\nCREATE USER readonly WITH ENCRYPTED PASSWORD 'ropass';\n```\n### 用户只读事务\n```\nalter user readonly set default_transaction_read_only=on;\n```\n### 把所有库的语言的USAGE权限给到readonly\n```\nGRANT USAGE ON SCHEMA public to readonly;\n```\n### 授予select权限(这句要进入具体数据库操作在哪个db环境执行就授予那个db的权)\n```\ngrant select on all tables in schema public to readonly;\n```\n","cover":"/images/zsh.png","link":"postgre_readonly_user.html","preview":"","title":"Postgre readonly user"},{"content":"\n\u003e 项目马上要启用HTTPS，先找个东西练手\n- 先生成一个RSA的key，加密算法选择aes也行，des3也行。这里使用1024位的des3。\n```bash\nopenssl genrsa -des3 -out ssl.key 1024\n```\n\u003e 会提示必须输入一个密码，随便输入一个就行了，下面我们要解密后才给nginx使用。\n\n```bash\nopenssl rsa -in ssl.key -out fm.key\n```\n- 然后用这个key来生成一个证书请求。\n\n```bash\nopenssl req -new -key fm.key -out fm.csr\n```\n\u003e 接着按照提示，输入证书的信息。\n\n- 得到csr文件后，通过下面命令生成一个自签名的证书，x509是证书的格式，3650表示证书有效期为10年。\n\n```bash\nopenssl x509 -req -days 3650 -in fm.csr -signkey fm.key -out fm.crt\n```\n\u003e 有了fm.crt和fm.key，就可以在nginx上搭建https的服务了\n\n- 下面是nginx的server段配置参考\n```nginx\nserver {\n    listen 443 ssl deferred spdy;\n    server_name 120.24.x.x;\n    root /data/fm/www;\n    ssl on;\n    ssl_certificate /data/fm/online/certs/fm.crt;\n    ssl_certificate_key /data/fm/online/certs/fm.key;\n    ssl_session_cache shared:SSL:50m;\n    ssl_session_timeout 5m;\n \t...  ...\n}\n```\n\u003e 最后提供一个[免费证书申请](https://buy.wosign.com/free/) 自用也可用选择Let's Encrypt 只是蛋疼的DNS解析，如果这个解决还是非常不错的。\n","cover":"/images/zsh.png","link":"nginx_https.html","preview":"","title":"使用自签证书部署HTTPS"},{"content":"\n\u003e 为了更好的学习自动化运维，就必须学习配置管理工具，Ansible 比较好入门所以从它开始\n\n## 安装和配置\n\n### 安装\n```bash\nsudo pip install ansible\n```\n创建并编辑ansible的hosts文件，内容为已经配置ssh免密码登录的远程主机的地址。\n/etc/ansible/hosts是默认路径\n```bash\nsudo mkdir /etc/ansible\nsudo vi /etc/ansible/hosts\n```\n内容为INI格式：\n```ini\n192.168.1.134\n192.168.1.136\n```\n也可以进行分组，同一个机器可以在不同分组\n```ini\n[v1]\n192.168.1.134\n\n[v2]\n192.168.1.136\n```\n如果远程的ssh端口修改了不在22标准端口，文件内容中机器地址应该明确指定端口号如：```192.168.1.134:2222```\n\n配置ssh免密码登录远程主机：\n\n当前用户名与远程机器上相同，ssh key在默认位置\n```bash\nssh-copy-id 192.168.1.136\nssh-copy-id 192.168.1.134\n```\n避免重复输入密钥的短语密码：\n```bash\nssh-add ~/.ssh/id_rsa\n```\n在本地测试是否能够ping通：\n\nping全部机器\n```bash\nansible all -m ping\n```\n\n以ashin用户身份ping .134\n```bash\nansible 192.168.1.134 -m ping -u ashin\n```\n\n以用户ashin身份使用sudo来ping v1 (.134) -K是输入root密码\n```bash\nansible v1 -m ping -u ashin --sudo -K\n```\n### 配置\n配置文件可以从多个地方加载，其优先级顺序为：\n```\nANSIBLE_CONFIG (环境变量)\nansible.cfg (当前目录)\n.ansible.cfg (home目录)\n/etc/ansible/ansible.cfg\n```\n定义自己的配置文件可以参考https://raw.githubusercontent.com/ansible/ansible/devel/examples/ansible.cfg\n\nssh检查key是通过paramiko进行的，很慢。 不检查host key配置：\n```bash\nsudo vi etc/ansible/ansible.cfg or ~/.ansible.cfg\n```\n内容为：\n```ini\n[defaults]\nhost_key_checking = False\n```\n","cover":"/images/avatar.png","link":"ansible_study_0x1.html","preview":"","title":"Ansible study note 00x01"},{"content":"\n\u003e 出现这个或者fatal error: openssl/*.h: No such file or directory。都是没有安装libssl-dev\n  libssl-dev包含libraries, header files and manpages，他是openssl的一部分，而openssl对ssl进行了实现～\n\n### 解决方案:\n```\nsudo apt-get install libssl-dev\n```\n安装libssl-dev即可\n","cover":"/images/zsh.png","link":"openssl-error.html","preview":"","title":"fatal error: openssl/opensslv.h: No such file or directory"},{"content":"\n最近app百石堂上线后，添加了不少android和iphone的应用下载，但发现了一个问题：在使用nginx提供下载.ipa或.apk文件时会出现以下问题：通过IE浏览器下载会出现替换扩展名为.zip；而使用火狐浏览器下载则会出现流的形式，就是不会下载，而是以乱码的形式浏览，显然这都不是我们想要的。\n下面我们先来了解下 nginx下conf/mime.types内各类型文件头信息：\n\n```\ntext/vnd.sun.j2me.app-descriptor      jad;   \napplication/java-archive              jar war ear;   \napplication/x-java-archive-diff       jardiff;   \napplication/vnd.android.package-archive apk;   \napplication/vnd.ms-cab-compressed     cab;   \napplication/octet-stream              bin exe dll;   \napplication/vnd.symbian.install       sis;   \nx-epoc/x-sisx-app                     sisx;   \napplication/iphone                    pxl ipa;   \napplication/vnd.palm                  prc pdb;   \napplication/vnd.webos.ipk             ipk;   \napplication/vnd.rim.cod               cod;   \napplication/mrp                       mrp;   \nx-nokia-widget                        wgz;   \napplication/octet-stream              deb;\n```\n\u003e目前许多提供下载.apk和.ipa的地方，用IE浏览器下载完后文件自动变成了zip后缀，导致无法使用，只要在nginx的conf/mime.typs内加上\n\n```\napplication/vnd.android.package-archive apk;   \napplication/iphone          pxl ipa;\n```\n","cover":"/images/zsh.png","link":"nginx_apk_download_config.html","preview":"","title":"Apk/ipk download config for nginx"},{"content":"\n\u003e使用电信的光纤送的猫都使用的是内部拨号，想使用路由桥接拨号必须用超级管理员登录改配置\n\n## 方法1：\n1. 光猫背面有useradmin密码，用这个账号登录192.168.1.1，地址栏输入http://192.168.1.1/backupsettings.conf\n2. 下载backupsettings.conf\n\n## 方法2：\n1. 把电脑IP设为 192.168.1.10 在操作电脑上安装 Cisco TFTP Server  ,开启 TFTP服务\n2. 下载putty，用 PUTTY 登陆 192.168.1.1   用户：admin  密码:admin 或是 空格\n3. 在SSH模式下输入 tftp -p -f backupsettings.conf 192.168.1.10  （就是下载光猫上的backupsettings.conf文件）\n\n\n\u003ebackupsettings.conf里面会存有超级用户密码找到 telecomadmin开头的这行，Password中间的那个就是密码（密码一般是telecomadmin+后面的数字）\n","cover":"/images/avatar.png","link":"cracktelecom.html","preview":"","title":"大亚光猫破解"},{"content":"\n在大家使用github的过程中，https方式每次要push 和pull时总是要输入github的账号和密码，这样不仅浪费了大量的时间且降低了工作效率。\n在网上发现以下方法可以免输入帐号密码：\n\n```bash\n$ cd ~\n$ touch .git-credentials\n$ echo \"https://{username}:{password}@github.com\" \u003e .git-credentials  //使用自己的帐号密码替换{username} {password}\n$ git config --global credential.helper store\n```\n\n然后再执行git push/pull无需再输入用户名和密码.\n","cover":"/images/zsh.png","link":"gitnopass.html","preview":"","title":"Git https push\u0026pull with no password"},{"content":"\nsequence 是一种特殊的数据库对象，用来产生独一无二的数字ID。Postgres中有一种数据类型serial，和sequence对应: \n![sequence1](http://blog.chinaunix.net/attachment/201311/2/24774106_1383400523Gg17.png)\n\n如果我们插入一笔记录，我们希望系统自动为我们分配一个ID，那么我们需要使用serial type。如果我们创建表的时候，自动创建一个serial类型（包smallserial and bigserial），系统会自动帮我们创建sequence这种数据库对象。\n```sql\ncreate table employ(\n      id serial,\n      name varchar(64),\n      department varchar(64)\n) ;\n\nmanu_db=# create table employ(id serial,name varchar(64),department varchar(128)) ;\nNOTICE:  CREATE TABLE will create implicit sequence \"employ_id_seq\" for serial column \"employ.id\"\nCREATE TABLE\nmanu_db=# \\d\n             List of relations\n Schema |     Name      |   Type   | Owner \n--------+---------------+----------+-------\n public | employ        | table    | manu\n public | employ_id_seq | sequence | manu\n(2 rows)\nmanu_db-# \\d employ\n                                   Table \"public.employ\"\n   Column   |          Type          |                      Modifiers                      \n------------+------------------------+-----------------------------------------------------\n id         | integer                | not null default nextval('employ_id_seq'::regclass)\n name       | character varying(64)  | \n department | character varying(128) | \n```\n我们看到，postgres自动帮助我们创建了一个sequence，命名原则是 tablename_columnname_seq.\n下面这两条SQL，本质是相等：\n```sql\nCREATE TABLE employ (\n      id serial,\n      name varchar(64),\n      department varchar(64)\n) ;\n```\n```sql\nCREATE SEQUENCE employ_id_seq ;\nCREATE TABLE employ (\n     id integer NOT NULL DEFAULT nextval('employ_id_seq'),\n     name varchar(64),\n     department varchar(64)\n);\n\nALTER SEQUENCE employ_id_seq OWNED by employ.id;\n```\n我们看到，我们用了integer数据类型和serial对应起来，默认用nextal（‘employ_id_seq’）给integer类型的id赋值，那是因为integer范围要比serial的范围大，这样做是安全的。对于bigserial，我们应该用bigint类型，对于smallserial应该何smallint对应。\n![sequence2](http://blog.chinaunix.net/attachment/201311/2/24774106_1383403462iqY7.png)    \n我们建立数据表和sequence的对应关系，常规的就是这两种方法，要么创建表的时候，某字段是serial类型，要么创建先创建sequence，然后创建表的时候，将某字段和sequence 联系起来（DEFAULT nextvl（‘XXXX_seq’））,有没有第三种方法？假如创建表的时候，没有用DEFAULT nextval建立起来联系，还有没有机会在后面建立这种联系？我为什么纠结这个？ \n```sql\nmanu_db=# create table employ_copy (like  employ) ;\nCREATE TABLE\nmanu_db=# \\d employ_copy \n           Table \"public.employ_copy\"\n   Column   |          Type          | Modifiers \n------------+------------------------+-----------\n id         | integer                | not null\n name       | character varying(64)  | \n department | character varying(128) | \n\n\nmanu_db=# \\d employ\n                                   Table \"public.employ\"\n   Column   |          Type          |                      Modifiers                      \n------------+------------------------+-----------------------------------------------------\n id         | integer                | not null default nextval('employ_id_seq'::regclass)\n name       | character varying(64)  | \n department | character varying(128) | \n\n\nmanu_db=# \n```\n如果业务需要，创建一个schema和employ一模一样的table，我们只能够用like，但是，我们看到，id这个字段并不完全一样，原因就是没有sequence和新建的table对应。这种情况，我们有没有办法，事后创建sequence，建立table中id字段的联系， I mean  id use nextval as default？\n答案是肯定的：\n```sql\nCREATE SEQUENCE employ_copy_id_seq ;\nALTER TABLE employ_copy ALTER COLUMN id SET DEFAULT nextval('employ_copy_id_seq');\nALTER SEQUENCE employ_copy_id_seq  OWNED by employ_copy.id ;\n```\n    看看效果：  \n```sql\nmanu_db=# CREATE SEQUENCE employ_copy_id_seq ;\nCREATE SEQUENCE\nmanu_db=# ALTER TABLE employ_copy ALTER COLUMN id SET DEFAULT nextval('employ_copy_id_seq');\nALTER TABLE\nmanu_db=# \\d employ_copy\n                                   Table \"public.employ_copy\"\n   Column   |          Type          |                        Modifiers                         \n------------+------------------------+----------------------------------------------------------\n id         | integer                | not null default nextval('employ_copy_id_seq'::regclass)\n name       | character varying(64)  | \n department | character varying(128) | \n```\n\n注意，加了alter sequence owned by ,在删除table的时候，会自动的将sequence删掉。如果不建立这种owned by的关系，删除table，不会引发sequence被删除。我就不贴了，可以自己try。\n\n当我们向Postgres插入一笔记录的时候，我们不需要费力告诉DB id的值，因为DB会自动分配一个数值给id：\n```sql\nmanu_db=# insert into  employ (name,department) values('bean', 'DDI');\nINSERT 0 1\nmanu_db=# insert into  employ (name,department) values('albert', 'DDI');\nINSERT 0 1\nmanu_db=# select * from employ ;\n id |  name  | department \n----+--------+------------\n  1 | bean   | DDI\n  2 | albert | DDI\n(2 rows)\n```\n我们可以用currval 和 nextval取到sequence的当前值和下一个值。注意，currval是不会改变sequence的，但是nextval一旦使用，下个数字就被消耗掉了，哪怕你并没有真正的用于你的table。\n```sql\nmanu_db=# select currval('employ_id_seq');\n currval \n---------\n       2\n(1 row)\n\nmanu_db=# select nextval('employ_id_seq');\n nextval \n---------\n       3\n(1 row)\n\nmanu_db=# select nextval('employ_id_seq');\n nextval \n---------\n       4\n(1 row)\n```\n使用setval可以设置下一个当前值，下一次就会从你设置的这个值开始递增：\n```sql  \nmanu_db=# select setval('employ_id_seq',100);\n setval \n--------\n    100\n(1 row)\n\nmanu_db=# select currval('employ_id_seq');\n currval \n---------\n     100\n(1 row)\n\nmanu_db=# select nextval('employ_id_seq');\n nextval \n---------\n     101\n(1 row)\n```\n***\n### 快速修改id的自增起始数为当前最大的id\n- 使用语句: ```select setval('your_table_id_seq',(select max(id) from \u003ctablename\u003e));```\n- 如何查看: ```your_table_id_seq?```\n- 使用命令: ```\\d \u003ctablename\u003e```\n\n\u003e  转载自[Bean_lee 's PostgreSQL之sequence](http://blog.chinaunix.net/uid-24774106-id-3973781.html)\n\n","cover":"/images/zsh.png","link":"postgre_sequence.html","preview":"","title":"Postgre sequence"},{"content":"\nUbuntu 14.04 的内核过于老旧，项目需要升级内核，现在把更新方式记录下来，以便不时之需.\n\n1. 查看当前内核版本\n```bash\n$ uname -r\n3.19.0-21-generic\n```\n\n2. 从[kernel.ubuntu.com](http://kernel.ubuntu.com/~kernel-ppa/mainline/)选择相应的内核版本文件下载到本地\n```bash\n$ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4-wily/linux-headers-4.4.0-040400_4.4.0-040400.201601101930_all.deb\n$ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.4-wily/linux-image-4.4.0-040400-generic_4.4.0-040400.201601101930_amd64.deb\n```\n3. 在下载目录执行安装\n```bash\n$ sudo dpkg -i linux-headers-4.4.0*.deb linux-image-4.4.0*.deb \n```\n4. 更新GRUB后重启系统\n```bash\n$ sudo update-grub\n```\n5. 查看当前系统内核，删除旧的内核\n```bash\n$ uname -r\n4.4.0-040400-generic\n\n$ sudo apt-get autoremove linux-image-3.19.0-21-generic linux-headers-3.19.0-21 linux-headers-3.19.0-21-generic\n```\n","cover":"/images/zsh.png","link":"ubuntu-update-kernel.html","preview":"","title":"Ubuntu upgrade kernel to v4"},{"content":"\n\u003e 在ubuntu下用apt安装nodejs太坑，现在记录下另外两种安装方式以备用\n\n![Node](/images/nodejs.png)\n## 二进制包安装\n1. 官网下载二进制包,并解压到相应目录\n```bash\n$ wget https://nodejs.org/dist/v4.2.3/node-v4.2.3-linux-x64.tar.gz\n$ tar xvzf node-v4.2.3-linux-x64.tar.gz\n```\n2. 设置环境变量\n```bash\n$ vim ~/.bashrc\n\n#set nodejs env\nexport NODE_HOME=\"the Node path\"\nexport PATH=$NODE_HOME/bin:$PATH\nexport NODE_PATH=$NODE_HOME/lib/node_modules:$PATH\n```\n3. 设置生效\n```bash\n$ source ~/.bashrc\n```\n4. 设置npm国内镜像\n```bash\n$ npm config set registry http://registry.cnpmjs.org\n```\n\n## 源码安装\n1. 官网下载源码包,并解压到相应目录\n```bash\n$ wget https://nodejs.org/dist/v4.2.3/node-v4.2.3.tar.gz\n$ tar xvzf node-v4.2.3.tar.gz\n```\n2. 进入目录进行编译\n```bash\n$ ./configure --prefix=/usr/local/nodejs\n$ make \u0026\u0026 make install\n```\n3. 设置环境变量\n```bash\n$ vim ~/.bashrc\n#set nodejs env\nexport NODE_HOME=\"the Node path\"\nexport PATH=$NODE_HOME/bin:$PATH\nexport NODE_PATH=$NODE_HOME/lib/node_modules:$PATH\n```\n4. 设置生效\n```bash\n$ source ~/.bashrc\n```\n5. 设置npm国内镜像\n```bash\n$ npm config set registry http://registry.cnpmjs.org\n```\n","cover":"/images/zsh.png","link":"node-install.html","preview":"","title":"Ubuntu Nodejs install"},{"content":"\n\u003e一直以来都是putty ssh 到linxu下使用shell，试着用Cygwin来在windows中原生打造一个shell环境。Cygwin自带mintty很好用，基本配置后配合tmux或screen就可抛弃xshell/securecrt/putty等专用客户端了。\n![](/images/zsh.png)\n***\n### 以下是我的minity配色参考(.minttyrc)\n```\nBoldAsFont=no\nFont=Powerline Consolas\nFontHeight=12\nTransparency=medium\nCursorType=block\nTerm=xterm-256color\nBellFlash=no\nForegroundColour=215,215,215\nBackgroundColour=48,48,48\nCursorColour=135,175,215\nBlack=48,48,48\nRed=255,95,95\nGreen=175,215,135\nYellow=215,215,175\nBlue=135,215,255\nMagenta=215,175,215\nCyan=135,215,175\nWhite=215,215,215\nBoldBlack=48,48,48\nBoldRed=255,95,95\nBoldGreen=175,215,135\nBoldYellow=215,215,175\nBoldBlue=135,215,255\nBoldMagenta=215,175,215\nBoldCyan=135,215,175\nBoldWhite=215,215,215\nFontSmoothing=full\nAllowBlinking=yes\nLocale=zh_CN\nCharset=UTF-8\n```\n\n### Windows下安装Cygwin以及包管理器\nCygwin下也有类似Linux下包管理工具apt-cyg，可以方便的通过网络安装各种软件。\n1. 下载安装：http://cygwin.com/setup.exe\n2. 选择安装源及软件，如需安装apt-cyg需安装以下软件包：\n```\nwget\ntar\ngawk\nbzip2\ngit\n```\n3. Cygwin安装完成后打开Cygwin Terminal安装apt-cyg包管理器:\n```\n$ git clone https://github.com/transcode-open/apt-cyg.git\n$ cd apt-cyg\n$ install apt-cyg /bin\n```\n4. 完成后就可以使用apt-cyg安装软件包了，先设置源（这里使用网易源镜像）\n```\n$ apt-cyg -m http://mirrors.163.com/cygwin/\n$ apt-cyg install vim\n```\n\n### 安装zsh \u0026 oh-my-zsh，tmux，powerline\n1. 使用apt-cyg安装zsh：\n```\n$ apt-cyg install zsh\n```\n2. 编辑Cygwin快捷方式，使用zsh启动shell\n```\nD:\\cygwin64\\bin\\mintty.exe -i /Cygwin-Terminal.ico /bin/zsh --login\n```\n3. 安装配置oh-my-zsh\n```\n$ wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh\n```\n4. 安装tmux\n```\n$ apt-cyg install tmux\n```\n5. 安装powerline(Mintty需要使用patch过的字体才能正确显示符号)\n```\n$ pip install powerline-status\n```\n6. 使用[gpakosz](https://github.com/gpakosz/.tmux)tmux配置\n```\n$ cd\n$ rm -rf .tmux\n$ git clone https://github.com/gpakosz/.tmux.git\n$ ln -s .tmux/.tmux.conf\n$ cp .tmux/.tmux.conf.local \n```\n","cover":"/images/zsh.png","link":"windows-shell.html","preview":"","title":"Windows下使用Cygwin打造终极shell"},{"content":"\n![overlay](http://docs.daocloud.io/images/c/0/3/5/1/c03512523e75f366ecf8f40442cbd8b46b227d28-3.png)\nOverlayFS之前已经加入到了Ubuntu内核中，但是那并不是我们想要的。Overlay（没有FS）是一个不同的内核模块，因此你需要安装3.18（或者以上）的内核，Docker你需要安装Docker 1.4或者更高版本。\n1. 使用Docker info查看Docker运行信息\n\n```\n$ docker info\nContainers: 0\nImages: 6\nServer Version: 1.9.1\nStorage Driver: aufs\n Backing Filesystem: extfs\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.19.0-26-generic\nOperating System: Ubuntu 14.04.3 LTS\nCPUs: 4\nTotal Memory: 7.69 GiB\nName: DEV\nID: CKAS:JEPR:SA3D:WA54:YQ6U:36RS:R5BO:7CXV:NZDF:PPY4:ORES:UY3H\nWARNING: No swap limit support\n```\n2. 确认内核\u003e3.18并且模块overlay有没有被启用,如果\"$ lsmod | grep overlay\"没有返回,可以使用\"$ modprobe overlay\"加载内核模块 \n```\n$ uname -r\n3.19.0-21-generic\n\n$ lsmod | grep overlay\noverlay\n```\n3. For ubuntu ：在/etc/default/docker中给DOCKER_OPTS设置-s overlay\n```\n# Use DOCKER_OPTS to modify the daemon startup options.\nDOCKER_OPTS = \"-s overlay\"\n```\n\n4. For Centos7 : 编辑/etc/sysconfig/docker和/usr/lib/systemd/system/docker.service\n```\n# /etc/sysconfig/docker\n# Modify these options if you want to change the way the docker daemon runs\nOPTIONS=\"--storage-driver overlay\"\n\n# /usr/lib/systemd/system/docker.service\n[Unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network.target docker.socket\nRequires=docker.socket\n\n[Service]\nType=notify\nEnvironmentFile=/etc/sysconfig/docker\nExecStart=/usr/bin/docker daemon -H fd:// $OPTIONS\nMountFlags=slave\nLimitNOFILE=1048576\nLimitNPROC=1048576\nLimitCORE=infinity\n\n[Install]\nWantedBy=multi-user.target\n```\n\n5. 重启docker服务\n```\n$ sudo service docker restart\n```\n6. 使用Docker info查看Docker运行信息 Storage Driver 已经使用overlay\n```\n$ docker info\nContainers: 0\nImages: 6\nServer Version: 1.9.1\nStorage Driver: overlay\n Backing Filesystem: extfs\nExecution Driver: native-0.2\nLogging Driver: json-file\nKernel Version: 3.19.0-26-generic\nOperating System: Ubuntu 14.04.3 LTS\nCPUs: 4\nTotal Memory: 7.69 GiB\nName: DEV\nID: CKAS:JEPR:SA3D:WA54:YQ6U:36RS:R5BO:7CXV:NZDF:PPY4:ORES:UY3H\nWARNING: No swap limit support\n```\n","cover":"/images/zsh.png","link":"docker-overlay.html","preview":"","title":"Docker use overlay driver"},{"content":"\n  一直以来往github push代码都是要填入用户名密码，真是浪费不少时间，现在不用输密码真是酸爽。\n----------\n 1. 安装Git for windowns.\n\n 2. git clone 项目.\n\n 3. 生成ssh-key.\n```{bash}\n$ ssh-keygen -t rsa -C \"email@email.com\"\n```\n 4. 在用户的.ssh目录下会生成id_rsa和id_rsa.pub两个文件.\n\n 5. 记事本打开id_rsa.pub复制内容粘贴到github ssh-key页面.\n\n 6. 修改推送方法为ssh,再次推送就无需密码了.\n ```{bash}\n$ git remote -v\norigin  https://github.com/user/Myrepo.git (fetch)\norigin  https://github.com/user/Myrepo.git (push)\n$ git remote set-url origin git@github.com:user/Myrepo.git\n```\n","cover":"/images/zsh.png","link":"github-nokey-push.html","preview":"","title":"Windows下github免密码push"},{"content":"\n![Mark](http://7xnznd.com1.z0.glb.clouddn.com/wp-content/uploads/2015/11/wpid-966128b1ee224b2142d25de2bac65386.jpg \"Mark\")\n开始学习怎么去写一个blog，来记录tester转去Full-stack的过程。\n","cover":"/images/zsh.png","link":"test-to-full-stack.html","preview":"","title":"Test to Full-stack"},{"content":"\n\n## 纸小墨简介\n\n纸小墨（InkPaper）是一个GO语言编写的开源静态博客构建工具，可以快速搭建博客网站。它无依赖跨平台，配置简单构建快速，注重简洁易用与更优雅的排版。\n\n### 开始上手\n\n- 下载并解压 [Ink](http://www.chole.io/)，运行命令 `ink preview`\n\n  \u003e 注意：Linux/macOS下，使用 `./ink preview`\n\n- 使用浏览器访问 `http://localhost:8000` 预览。\n\n### 特性介绍\n- YAML格式的配置\n- Markdown格式的文章\n- 无依赖跨平台\n- 超快的构建速度\n- 不断改善的主题与排版\n- 多文章作者支持\n- 归档与标签自动生成\n- 保存时实时预览页面\n- 离线的全文关键字搜索\n\n### 配置网站\n编辑`config.yml`，使用如下格式：\n\n``` yaml\nsite:\n    title: 网站标题\n    subtitle: 网站子标题\n    limit: 每页可显示的文章数目\n    theme: 网站主题目录\n    comment: 评论插件变量(默认为Disqus账户名)\n    root: 网站根路径 #可选\n    lang: 网站语言 #支持en, zh, ru, ja，可在theme/config.yml配置\n    url: 网站链接 #用于RSS生成\n    link: 文章链接形式 #默认为{title}.html，支持{year},{month},{day},{title}变量\n\nauthors:\n    作者ID:\n        name: 作者名称\n        intro: 作者简介\n        avatar: 作者头像路径\n\nbuild:\n    output: 构建输出目录 #可选, 默认为 \"public\"\n    port: 预览端口\n    copy:\n        - 构建时将会复制的目录/文件\n    publish: |\n        ink publish 命令将会执行的脚本\n```\n\n### 创建文章\n在`source`目录中建立任意`.md`文件（可置于子文件夹），使用如下格式：\n\n``` yaml\ntitle: 文章标题\ndate: 年-月-日 时:分:秒 #创建时间，可加时区如\" +0800\"\nupdate: 年-月-日 时:分:秒 #更新时间，可选，可加时区如\" +0800\"\nauthor: 作者ID\ncover: 题图链接 #可选\ndraft: false #草稿，可选\ntop: false #置顶文章，可选\npreview: 文章预览，也可在正文中使用\u003c!--more--\u003e分割 #可选\ntags: #可选\n    - 标签1\n    - 标签2\ntype: post #指定类型为文章(post)或页面(page)，可选\nhide: false #隐藏文章，只可通过链接访问，可选\n\n---\n\nMarkdown格式的正文\n```\n\n### 发布博客\n- 在博客目录下运行`ink publish`命令自动构建博客并发布。\n- 或运行`ink build`命令将生成的`public`目录下的内容手动部署。\n\n\u003e Tips: 在使用`ink preview`命令时，编辑保存文件后，博客会自动重新构建并刷新浏览器页面。\n\n## 定制支持\n\n### 修改主题\n\n默认主题在`theme`目录下，修改源代码后在该目录下运行`npm install`与`npm run build`重新构建。\n\n页面包含`page.html`（文章列表）及`article.html`（文章）等，所有页面均支持[GO语言HTML模板](http://golang.org/pkg/html/template/)语法，可引用变量。\n\n### 添加页面\n\n在`source`目录下创建的任意`.html`文件将被复制，这些文件中可引用`config.yml`中site字段下的所有变量。\n\n### 博客迁移(Beta)\n\n纸小墨提供简单的Jeklly/Hexo博客文章格式转换，使用命令：\n``` shell\nink convert /path/_posts\n```\n\n### 源码编译\n\n本地运行\n\n1. 配置[GO](http://golang.org/doc/install)语言环境。\n2. 运行命令`go get github.com/InkProject/ink`，编译并获取ink。\n3. 运行命令`ink preview $GOPATH/src/github.com/InkProject/ink/template`，预览博客。\n\nDocker构建（示例）\n\n1. Clone源码 `git clone git@github.com:InkProject/ink.git`。\n2. 源码目录下构建镜像`docker build -t ink .`。\n3. 运行容器`docker run -p 8000:80 ink`。\n\n## 主题\n\n- Dark(Official Theme): [https://github.com/InkProject/ink-theme-dark](https://github.com/InkProject/ink-theme-dark)\n- simple: [https://github.com/myiq/ink-simple](https://github.com/myiq/ink-simple)\n\n## 使用Travis-ci来自动部署GithubPage\n\n### 建立Github Page仓库\n\n- 在Github上建立名为`yourname.github.com`的仓库\n\n \u003e 用该名字建立的仓库可用用`yourname.github.io`域名直接访问生成的博客页面。\n\n- 将纸小墨的源码push到非master分支上，我使用的是名为blog-src的分支。\n\n- 在源码根目录新建`.travis.yml`文件，填入下列内容并push到github上：\n\n``` yaml\nlanguage: go\n\ninstall:\n  - go get github.com/InkProject/ink\n  - ink build\n\nscript:\n  - cd ./blog/public/\n  - git init\n  - git config user.name \"yourname\"\n  - git config user.email \"yourname@gmail.com\"\n  - git add .\n  - git commit -m \"update blogs\"\n  - git push --force --quiet \"https://${GH_TOKEN}@${GH_REF}\" master:master\n\nbranches:\n  only:\n    - blog-src\nenv:\n  global:\n    - GH_REF: github.com/yourname/yourname.github.com\n```\n\n### 在Travis-ci.org上进行相关设置\n\n- 用你的 GitHub 账号登录 Travis CI。\n\n- 登录之后，请转到您的配置页，并为你想要构建的仓库启用 Travis CI 。\n\n- 在 Travis CI 里为对应的仓库添加 Github Access Token，用于后续使用 GitHub API. 这样 Travis CI 可以将通过 InkPaper 生成的静态博客源文件推送到 GitHub Pages 分支。","cover":"/images/ink-Travis.png","link":"ink-blog-ci.html","preview":"\u003cp\u003e纸小墨（InkPaper）是一个GO语言编写的开源静态博客构建工具，可以快速搭建博客网站。它无依赖跨平台，配置简单构建快速，注重简洁易用与更优雅的排版。\u003c/p\u003e\n","title":"使用Travis-ci和纸小墨（InkPaper）部署GithubPage"}]